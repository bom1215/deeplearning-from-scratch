{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.4 합성곱/풀링 계층 구현하기\n",
    "### 7.4.1 4차원 배열"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 1, 28, 28)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(1, 28, 28)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[0.74889139, 0.27610254, 0.34137729, 0.61994367, 0.91737665,\n",
       "        0.89751647, 0.8079344 , 0.19678818, 0.98692891, 0.171172  ,\n",
       "        0.0807035 , 0.3568013 , 0.74575297, 0.90463588, 0.31491693,\n",
       "        0.04738363, 0.44858268, 0.71847949, 0.39784587, 0.76465392,\n",
       "        0.07571548, 0.6193311 , 0.43459609, 0.05375284, 0.95126941,\n",
       "        0.6655919 , 0.68171682, 0.83473206],\n",
       "       [0.36177897, 0.37282158, 0.09157972, 0.44478709, 0.03796736,\n",
       "        0.70124527, 0.99660157, 0.6407871 , 0.495408  , 0.76084226,\n",
       "        0.21273683, 0.24002209, 0.13891527, 0.32957805, 0.02826579,\n",
       "        0.48590079, 0.42947526, 0.64052464, 0.06660279, 0.07260489,\n",
       "        0.79982405, 0.86805562, 0.98171806, 0.44989194, 0.70685372,\n",
       "        0.84967202, 0.41717162, 0.12290211],\n",
       "       [0.32414234, 0.52357886, 0.64517254, 0.09667518, 0.10166888,\n",
       "        0.66071083, 0.08356545, 0.95413696, 0.33926739, 0.38648055,\n",
       "        0.76011033, 0.51766856, 0.48281695, 0.39659225, 0.01956227,\n",
       "        0.05381265, 0.33629795, 0.92556612, 0.90356222, 0.8730232 ,\n",
       "        0.53516495, 0.89905542, 0.25342973, 0.43028317, 0.59903676,\n",
       "        0.19095558, 0.06282991, 0.3009134 ],\n",
       "       [0.57457058, 0.58490201, 0.83392387, 0.41354512, 0.21106758,\n",
       "        0.61555581, 0.62427117, 0.45589446, 0.73785493, 0.7840584 ,\n",
       "        0.48122443, 0.05593365, 0.81481571, 0.95940974, 0.00681515,\n",
       "        0.35705597, 0.90626429, 0.64376154, 0.47320592, 0.02922092,\n",
       "        0.55110223, 0.44258011, 0.24454672, 0.76351571, 0.30159314,\n",
       "        0.38780823, 0.90920348, 0.71627123],\n",
       "       [0.92780093, 0.65000372, 0.37541372, 0.5283853 , 0.55016361,\n",
       "        0.39013222, 0.04488909, 0.42949735, 0.43011802, 0.6117997 ,\n",
       "        0.52828559, 0.90046027, 0.47483365, 0.29642439, 0.80002795,\n",
       "        0.05744423, 0.20173697, 0.14737257, 0.71869547, 0.8455923 ,\n",
       "        0.58069155, 0.30155405, 0.24054575, 0.70646443, 0.42946093,\n",
       "        0.94694366, 0.10837816, 0.97587536],\n",
       "       [0.77831558, 0.88998838, 0.28238817, 0.46055925, 0.15512129,\n",
       "        0.23329845, 0.72607445, 0.93332927, 0.05705975, 0.64599318,\n",
       "        0.45802206, 0.48093279, 0.12363763, 0.61961827, 0.40128116,\n",
       "        0.4425925 , 0.91619238, 0.06072712, 0.98392144, 0.10971156,\n",
       "        0.90631173, 0.91587828, 0.21877542, 0.38577418, 0.43519571,\n",
       "        0.24085151, 0.27380541, 0.85515022],\n",
       "       [0.47859091, 0.49010443, 0.9214438 , 0.78556079, 0.12804411,\n",
       "        0.27639062, 0.8126387 , 0.37480038, 0.4201422 , 0.87531756,\n",
       "        0.47557644, 0.66180422, 0.36667782, 0.94860927, 0.99436585,\n",
       "        0.06172856, 0.31379319, 0.94763301, 0.44518779, 0.2830197 ,\n",
       "        0.39502246, 0.9199882 , 0.43250634, 0.12999031, 0.63448888,\n",
       "        0.11553435, 0.55001271, 0.77502047],\n",
       "       [0.49199002, 0.25875491, 0.31621269, 0.63410725, 0.61377437,\n",
       "        0.29213005, 0.98565685, 0.08406512, 0.55212573, 0.90727543,\n",
       "        0.56198122, 0.53251588, 0.60687108, 0.78925055, 0.85775911,\n",
       "        0.68450378, 0.9520229 , 0.06669509, 0.93670443, 0.11068094,\n",
       "        0.49957603, 0.69968913, 0.06810553, 0.83097956, 0.32956802,\n",
       "        0.04278812, 0.37435339, 0.0723285 ],\n",
       "       [0.1882397 , 0.62743096, 0.47740114, 0.93667111, 0.26883671,\n",
       "        0.44535365, 0.26480124, 0.9865435 , 0.66564548, 0.01050197,\n",
       "        0.71343172, 0.39438899, 0.42058484, 0.00530556, 0.79924566,\n",
       "        0.52354266, 0.43544245, 0.17542446, 0.23661785, 0.02789831,\n",
       "        0.93973724, 0.63435859, 0.17462867, 0.5625008 , 0.20832625,\n",
       "        0.47203751, 0.32842849, 0.8218724 ],\n",
       "       [0.50404928, 0.10958236, 0.95527964, 0.6293019 , 0.63120987,\n",
       "        0.62960183, 0.65335458, 0.90246865, 0.05701247, 0.29472172,\n",
       "        0.60527844, 0.85455023, 0.48221676, 0.68836936, 0.1441424 ,\n",
       "        0.39770568, 0.88416569, 0.89859989, 0.47540068, 0.47740834,\n",
       "        0.71346531, 0.31167661, 0.00281419, 0.52829097, 0.95343175,\n",
       "        0.67445763, 0.28118782, 0.67682613],\n",
       "       [0.49633365, 0.51718122, 0.50318432, 0.35849388, 0.09237586,\n",
       "        0.85810288, 0.34741297, 0.29587386, 0.72627464, 0.8103184 ,\n",
       "        0.47027273, 0.3200888 , 0.882205  , 0.96901228, 0.29328144,\n",
       "        0.89096978, 0.3778744 , 0.96063937, 0.5952744 , 0.63693457,\n",
       "        0.82301006, 0.53022407, 0.8449903 , 0.70705314, 0.95447484,\n",
       "        0.24028911, 0.48285596, 0.58665257],\n",
       "       [0.5444267 , 0.10128566, 0.20822205, 0.35159925, 0.94113925,\n",
       "        0.45993225, 0.0551402 , 0.93713128, 0.36760745, 0.53614645,\n",
       "        0.08376563, 0.15051653, 0.1611243 , 0.55497211, 0.2446275 ,\n",
       "        0.71400267, 0.68530043, 0.52373363, 0.21298379, 0.52797421,\n",
       "        0.37734098, 0.96753066, 0.86070962, 0.10033188, 0.55585642,\n",
       "        0.22462059, 0.59722194, 0.25585443],\n",
       "       [0.9112738 , 0.30925215, 0.57730273, 0.63250646, 0.13944385,\n",
       "        0.02556103, 0.94603094, 0.040019  , 0.49686766, 0.01350001,\n",
       "        0.09522767, 0.50715256, 0.46526559, 0.620466  , 0.46540695,\n",
       "        0.89267144, 0.50216055, 0.14604333, 0.77226929, 0.0870575 ,\n",
       "        0.79768242, 0.36878449, 0.41522244, 0.6275375 , 0.30204671,\n",
       "        0.81581191, 0.23111043, 0.46337775],\n",
       "       [0.17456636, 0.11321527, 0.91417183, 0.38605335, 0.51358052,\n",
       "        0.3244297 , 0.64444425, 0.63915943, 0.02636192, 0.98738181,\n",
       "        0.04277943, 0.42919974, 0.59403699, 0.2087361 , 0.70457   ,\n",
       "        0.93322536, 0.23226702, 0.64948844, 0.6272353 , 0.43757754,\n",
       "        0.75381222, 0.83430738, 0.4402617 , 0.9540282 , 0.33335137,\n",
       "        0.63009955, 0.47391569, 0.73998899],\n",
       "       [0.96140359, 0.20921772, 0.22136441, 0.30896621, 0.44592276,\n",
       "        0.84321396, 0.79273437, 0.85348155, 0.17680618, 0.16343338,\n",
       "        0.24486398, 0.78007574, 0.56651353, 0.59264798, 0.99332884,\n",
       "        0.85477406, 0.18591551, 0.63317475, 0.34289482, 0.65039497,\n",
       "        0.29393249, 0.47978861, 0.37285038, 0.23478179, 0.28118944,\n",
       "        0.15906658, 0.70058067, 0.2643031 ],\n",
       "       [0.63232752, 0.68988212, 0.9680393 , 0.4429911 , 0.09130872,\n",
       "        0.54072156, 0.0654338 , 0.7528185 , 0.25391463, 0.83379267,\n",
       "        0.74838286, 0.22120738, 0.23407758, 0.77312358, 0.93658758,\n",
       "        0.51243476, 0.33891068, 0.70435767, 0.98471029, 0.43230801,\n",
       "        0.94968942, 0.74170508, 0.46974652, 0.65828073, 0.4248829 ,\n",
       "        0.69063166, 0.68123823, 0.29754714],\n",
       "       [0.29296574, 0.57897303, 0.57743202, 0.80378797, 0.27881573,\n",
       "        0.43265629, 0.26273279, 0.52859492, 0.89930188, 0.68176002,\n",
       "        0.00236556, 0.7127631 , 0.01559008, 0.47433544, 0.47071434,\n",
       "        0.22604362, 0.04645686, 0.50229237, 0.97643121, 0.50115072,\n",
       "        0.48957942, 0.43723167, 0.82347946, 0.88140494, 0.80693021,\n",
       "        0.53308407, 0.40708486, 0.16027355],\n",
       "       [0.14460769, 0.39974368, 0.67191439, 0.0422012 , 0.63166205,\n",
       "        0.62515111, 0.09821097, 0.23591134, 0.14251083, 0.1685006 ,\n",
       "        0.15083075, 0.15071026, 0.78285067, 0.85453895, 0.28132035,\n",
       "        0.11071922, 0.66081896, 0.70215149, 0.99238377, 0.78501083,\n",
       "        0.4967501 , 0.07295523, 0.0327849 , 0.75023194, 0.52515517,\n",
       "        0.76727743, 0.0217351 , 0.6194625 ],\n",
       "       [0.87400622, 0.84653311, 0.52177726, 0.21717799, 0.26017931,\n",
       "        0.79938912, 0.48000327, 0.36068945, 0.43583477, 0.65760057,\n",
       "        0.16774897, 0.46525736, 0.11095775, 0.63567992, 0.9359229 ,\n",
       "        0.89031436, 0.18058554, 0.21701711, 0.09207154, 0.04086257,\n",
       "        0.63928156, 0.48211298, 0.54518443, 0.53614452, 0.83677124,\n",
       "        0.79621324, 0.95359034, 0.54782888],\n",
       "       [0.66211705, 0.60588599, 0.86879073, 0.55116112, 0.93460605,\n",
       "        0.73259114, 0.39370802, 0.32116226, 0.36936942, 0.44832494,\n",
       "        0.35402905, 0.59519647, 0.40121662, 0.60731384, 0.11256124,\n",
       "        0.26864478, 0.67718938, 0.82870881, 0.40755729, 0.39968908,\n",
       "        0.93120323, 0.82132475, 0.10963378, 0.23022382, 0.73246784,\n",
       "        0.92818077, 0.34845487, 0.7258268 ],\n",
       "       [0.35278425, 0.37528347, 0.5417389 , 0.85393504, 0.77847105,\n",
       "        0.77621639, 0.65619387, 0.11262364, 0.03284886, 0.84216316,\n",
       "        0.445078  , 0.87610859, 0.14486849, 0.35716985, 0.02250615,\n",
       "        0.16451514, 0.09836723, 0.41890405, 0.85719324, 0.52967788,\n",
       "        0.68472218, 0.31760504, 0.43799024, 0.24488938, 0.48889013,\n",
       "        0.52193829, 0.97560635, 0.48767871],\n",
       "       [0.9046948 , 0.104436  , 0.04509383, 0.55218696, 0.52370617,\n",
       "        0.20862871, 0.50990844, 0.8691057 , 0.63156339, 0.30960957,\n",
       "        0.2807915 , 0.68448204, 0.601807  , 0.08673209, 0.0169372 ,\n",
       "        0.4391935 , 0.88236263, 0.28738214, 0.08700391, 0.1887774 ,\n",
       "        0.62020056, 0.07963322, 0.83356363, 0.627947  , 0.51375675,\n",
       "        0.2344372 , 0.68052236, 0.9740291 ],\n",
       "       [0.58236013, 0.36654581, 0.91637797, 0.98345707, 0.2024447 ,\n",
       "        0.4353604 , 0.05798287, 0.64256433, 0.36142906, 0.9482467 ,\n",
       "        0.7052146 , 0.3800275 , 0.69030549, 0.62061611, 0.89016274,\n",
       "        0.17300634, 0.59901673, 0.84354739, 0.94295055, 0.86586704,\n",
       "        0.35633214, 0.14261573, 0.61746012, 0.47769743, 0.94416432,\n",
       "        0.57370291, 0.34860859, 0.70934658],\n",
       "       [0.37244205, 0.95139586, 0.68852742, 0.12837995, 0.04523356,\n",
       "        0.74646552, 0.35043458, 0.95611295, 0.42146736, 0.22779824,\n",
       "        0.49145775, 0.02591729, 0.77012744, 0.49417341, 0.44932174,\n",
       "        0.0432172 , 0.75936584, 0.61179409, 0.1957287 , 0.63406394,\n",
       "        0.87116014, 0.54831178, 0.26125489, 0.45022396, 0.50938407,\n",
       "        0.15124068, 0.66410979, 0.2664204 ],\n",
       "       [0.72931466, 0.25597268, 0.13890221, 0.33099825, 0.63713163,\n",
       "        0.57200887, 0.59535038, 0.20968296, 0.79211263, 0.41512615,\n",
       "        0.36387494, 0.18511578, 0.24900653, 0.4190471 , 0.06841438,\n",
       "        0.44426551, 0.44149949, 0.55196756, 0.34415179, 0.38245641,\n",
       "        0.7672645 , 0.69889023, 0.10874775, 0.33852743, 0.90141673,\n",
       "        0.93382234, 0.7149441 , 0.62429889],\n",
       "       [0.00756984, 0.26669414, 0.91198421, 0.36123711, 0.99411979,\n",
       "        0.809249  , 0.59262793, 0.99125781, 0.54828085, 0.61772048,\n",
       "        0.23034622, 0.37569417, 0.52966685, 0.10062053, 0.74643094,\n",
       "        0.19532884, 0.95680008, 0.21688332, 0.46653353, 0.43418092,\n",
       "        0.40614554, 0.03526376, 0.42123171, 0.03206542, 0.52582165,\n",
       "        0.68864321, 0.45561272, 0.72475062],\n",
       "       [0.74951543, 0.9988348 , 0.12195272, 0.31615405, 0.69712331,\n",
       "        0.59618881, 0.46105669, 0.81258596, 0.69937772, 0.18802909,\n",
       "        0.32244778, 0.70755098, 0.4953058 , 0.72494531, 0.83170864,\n",
       "        0.95872234, 0.80971153, 0.36306664, 0.24076359, 0.11048491,\n",
       "        0.07200154, 0.36838498, 0.40956529, 0.62081489, 0.75307283,\n",
       "        0.31430162, 0.21853672, 0.42007113],\n",
       "       [0.55998795, 0.01287551, 0.35793366, 0.93848427, 0.96811995,\n",
       "        0.43214932, 0.38129313, 0.72469141, 0.25548455, 0.50697107,\n",
       "        0.85880661, 0.03260348, 0.31203692, 0.04327324, 0.74240716,\n",
       "        0.59078984, 0.0906867 , 0.86085549, 0.5043726 , 0.01285679,\n",
       "        0.37618541, 0.15832493, 0.64574117, 0.64370993, 0.69491414,\n",
       "        0.00680128, 0.51199912, 0.76174342]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.random.rand(10, 1, 28, 28)\n",
    "x.shape\n",
    "x[0].shape\n",
    "x[0,0] # 또는 x[0][0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.4.3 합성곱 계층 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9, 75)\n",
      "(90, 75)\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.pardir)\n",
    "from common.util import im2col\n",
    "\n",
    "x1 = np.random.rand(1,3,7,7) #(데이터 수, 채널 수, 높이, 너비)\n",
    "col1 = im2col(x1, 5, 5, stride=1, pad=0)\n",
    "print(col1.shape)\n",
    "\n",
    "x2 = np.random.rand(10, 3, 7, 7) # 데이터 10개\n",
    "col2 = im2col(x2, 5, 5, stride=1, pad=0)\n",
    "print(col2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Convolution:\n",
    "    def __init__(self, W, b, stride=1, pad=0):\n",
    "        self.W = W\n",
    "        self.b = b\n",
    "        self.stride = stride\n",
    "        self.pad = pad\n",
    "    \n",
    "    def forward(self, x):\n",
    "        FN, C, FH, FW = self.W.shape #필터의 개수, 채널 수, 필터의 높이, 필터의 너비\n",
    "        N, C, H, W = x.shape # 데이터 개수, 채널 수, 데이터 높이, 데이터 너비\n",
    "        out_h = int(1 + (H + 2*self.pad - FH) / self.stride) # 합성곱 신경망 통과 후 높이\n",
    "        out_w = int(1 + (W + 2*self.pad - FW) / self.stride) # 합성곱 신경망 통과 후 너비\n",
    "\n",
    "        col = im2col(x, FH, FW, self.stride, self.pad)\n",
    "        col_W = self.W.reshape(FN, -1).T #필터 전개\n",
    "        out = np.dot(col, col_W) + self.b\n",
    "        \n",
    "        out = out.reshape(N, out_h, out_w, -1).transpose(0,3,1,2) # 인덱스로 축의 순서 변경 p247\n",
    "\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Pooling:\n",
    "    def __init__(self, pool_h, pool_w, stride=1, pad=0):\n",
    "        self.pool_h = pool_h\n",
    "        self.pool_w = pool_w\n",
    "        self.stride = stride\n",
    "        self.pad = pad\n",
    "    \n",
    "    def forward(self, x):\n",
    "        N, C, H, W = x.shape\n",
    "        out_h = int(1 + (H - self.pool_h)/ self.stride)\n",
    "        out_w = int(1 + (W - self.pool_w) / self.stride)\n",
    "\n",
    "        # 전개 (1)\n",
    "        col = im2col(x, self.pool_h, self.pool_w, self.stride, self.pad)\n",
    "        col = col.reshape(-1, self.pool_h*self.pool_w)\n",
    "\n",
    "        # 최댓값 (2)\n",
    "        out = np.max(col, axis=1)\n",
    "\n",
    "        # 성형 (3)\n",
    "        out = out.reshape(N, out_h, out_w, C).transpose(0,3,1,2)\n",
    "\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "from common.layers import Relu, Affine, SoftmaxWithLoss, Pooling, Convolution\n",
    "class SimpleConvNet:\n",
    "    def __init__(self, input_dim = (1,28,28),\n",
    "                 conv_param={'filter_num':30, 'filter_size':5,\n",
    "                            'pad':0, 'stride':1},\n",
    "                 hidden_size = 100, output_size=10, weight_init_std=0.01):\n",
    "        filter_num = conv_param['filter_num']\n",
    "        filter_size = conv_param['filter_size']\n",
    "        filter_pad = conv_param['pad']\n",
    "        filter_stride = conv_param['stride']\n",
    "        input_size = input_dim[1]\n",
    "        conv_output_size = (input_size - filter_size + 2*filter_pad) / filter_stride + 1\n",
    "        pool_output_size = int(filter_num * (conv_output_size/2)* (conv_output_size/2))\n",
    "\n",
    "        self.params = {}\n",
    "        self.params['W1'] = weight_init_std * np.random.randn(filter_num, input_dim[0], filter_size, filter_size) #CNN 가중치\n",
    "        self.params['b1'] = np.zeros(filter_num)\n",
    "        self.params['W2'] = weight_init_std * np.random.randn(pool_output_size, hidden_size) # 완전연결계층 가중치\n",
    "        self.params['b2'] = np.zeros(hidden_size)\n",
    "        self.params['W3'] = weight_init_std * np.random.randn(hidden_size, output_size) # 완전연결계층 가중치\n",
    "        self.params['b3'] = np.zeros(output_size)\n",
    "\n",
    "        self.layers = OrderedDict()\n",
    "        self.layers['Conv1'] = Convolution(self.params['W1'], self.params['b1'], conv_param['stride'],conv_param['pad'])\n",
    "        self.layers['Relu1'] = Relu()\n",
    "        self.layers['Pool1'] = Pooling(pool_h=2, pool_w=2, stride=2)\n",
    "        self.layers['Affine1'] = Affine(self.params['W2'], self.params['b2'])\n",
    "        self.layers['Relu2'] = Relu()\n",
    "        self.layers['Affine2'] = Affine(self.params['W3'], self.params['b3'])\n",
    "        \n",
    "        self.last_layer = SoftmaxWithLoss()\n",
    "    \n",
    "    def predict(self, x):\n",
    "        for layer in self.layers.values():\n",
    "            x = layer.forward(x)\n",
    "        return x\n",
    "    \n",
    "    def loss(self, x, t):\n",
    "        y = self.predict(x)\n",
    "        return self.last_layer.forward(y, t)\n",
    "    \n",
    "    def gradient(self, x, t):\n",
    "        #순전파\n",
    "        self.loss(x, t)\n",
    "        \n",
    "        #역전파\n",
    "        dout = 1\n",
    "        dout = self.last_layer.backward(dout)\n",
    "\n",
    "        layers = list(self.layers.values())\n",
    "        layers.reverse()\n",
    "        for layer in layers:\n",
    "            dout = layer.backward(dout)\n",
    "\n",
    "        # 결과 저장\n",
    "        grads = {}\n",
    "        grads['W1'] = self.layers['Conv1'].dW\n",
    "        grads['b1'] = self.layers['Conv1'].db\n",
    "        grads['W2'] = self.layers['Affine1'].dW\n",
    "        grads['b2'] = self.layers['Affine1'].db\n",
    "        grads['W3'] = self.layers['Affine2'].dW\n",
    "        grads['b3'] = self.layers['Affine2'].db\n",
    "\n",
    "        return grads\n",
    " \n",
    "    def accuracy(self, x, t): # 새롭게 추가 (from ch4_back_propagation)\n",
    "        y = self.predict(x)\n",
    "        y = np.argmax(y, axis = 1)\n",
    "        if t.ndim != 1 : t = np.argmax(t, axis=1)\n",
    "\n",
    "        accuracy = np.sum(y == t) / float(x.shape[0])\n",
    "\n",
    "        return accuracy\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600.0\n",
      "epoch 0\n",
      "loss:  2.304784320814451\n",
      "test_acc:  0.0846\n",
      "epoch 100\n",
      "epoch 200\n",
      "epoch 300\n",
      "epoch 400\n",
      "epoch 500\n",
      "epoch 600\n",
      "loss:  0.11589606454499154\n",
      "test_acc:  0.94\n",
      "epoch 700\n",
      "epoch 800\n",
      "epoch 900\n",
      "epoch 1000\n",
      "epoch 1100\n",
      "epoch 1200\n",
      "loss:  0.11527281013289763\n",
      "test_acc:  0.9584\n",
      "epoch 1300\n",
      "epoch 1400\n",
      "epoch 1500\n",
      "epoch 1600\n",
      "epoch 1700\n",
      "epoch 1800\n",
      "loss:  0.08976647872153644\n",
      "test_acc:  0.9668\n",
      "epoch 1900\n",
      "epoch 2000\n",
      "epoch 2100\n",
      "epoch 2200\n",
      "epoch 2300\n",
      "epoch 2400\n",
      "loss:  0.029601223826169275\n",
      "test_acc:  0.9717\n",
      "epoch 2500\n",
      "epoch 2600\n",
      "epoch 2700\n",
      "epoch 2800\n",
      "epoch 2900\n",
      "epoch 3000\n",
      "loss:  0.03241272556792776\n",
      "test_acc:  0.9771\n",
      "epoch 3100\n",
      "epoch 3200\n",
      "epoch 3300\n",
      "epoch 3400\n",
      "epoch 3500\n",
      "epoch 3600\n",
      "loss:  0.028027080486256795\n",
      "test_acc:  0.9773\n",
      "epoch 3700\n",
      "epoch 3800\n",
      "epoch 3900\n",
      "epoch 4000\n",
      "epoch 4100\n",
      "epoch 4200\n",
      "loss:  0.03084554204923514\n",
      "test_acc:  0.9803\n",
      "epoch 4300\n",
      "epoch 4400\n",
      "epoch 4500\n",
      "epoch 4600\n",
      "epoch 4700\n",
      "epoch 4800\n",
      "loss:  0.03527169840896817\n",
      "test_acc:  0.982\n",
      "epoch 4900\n",
      "epoch 5000\n",
      "epoch 5100\n",
      "epoch 5200\n",
      "epoch 5300\n",
      "epoch 5400\n",
      "loss:  0.022852831006219668\n",
      "test_acc:  0.9794\n",
      "epoch 5500\n",
      "epoch 5600\n",
      "epoch 5700\n",
      "epoch 5800\n",
      "epoch 5900\n",
      "epoch 6000\n",
      "loss:  0.018809631988709143\n",
      "test_acc:  0.9828\n",
      "epoch 6100\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[37], line 43\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;66;03m# print(\"grad[W1]: \",np.count_nonzero(grad['W1']))\u001b[39;00m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m# print(\"grad['b1']: \",grad['b1'])\u001b[39;00m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;66;03m# print(\"grad['W2']: \",grad['W2'])\u001b[39;00m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m# print(\"grad['b2']: \",grad['b2'])\u001b[39;00m\n\u001b[0;32m     40\u001b[0m \n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m# 갱신\u001b[39;00m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mW1\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mb1\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mW2\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mb2\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mW3\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mb3\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m---> 43\u001b[0m     network\u001b[38;5;241m.\u001b[39mparams[key] \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m learning_rate \u001b[38;5;241m*\u001b[39m grad[key]\n\u001b[0;32m     45\u001b[0m loss \u001b[38;5;241m=\u001b[39m network\u001b[38;5;241m.\u001b[39mloss(x_batch, t_batch)\n\u001b[0;32m     46\u001b[0m \u001b[38;5;66;03m# print(\"loss: \",loss)\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 데이터 읽기\n",
    "from dataset.mnist import MnistDataloader\n",
    "mnist_dataloader = MnistDataloader()\n",
    "(x_train, t_train), (x_test, t_test) = mnist_dataloader.load_data()\n",
    "\n",
    "network  = SimpleConvNet()\n",
    "\n",
    "iters_num = 10000\n",
    "train_size = x_train.shape[0]\n",
    "batch_size = 100\n",
    "learning_rate = 0.001\n",
    "\n",
    "train_loss_list = []\n",
    "train_acc_list = []\n",
    "test_acc_list = []\n",
    "\n",
    "iter_per_epoch = max(train_size / batch_size, 1)\n",
    "print(iter_per_epoch)\n",
    "\n",
    "x_train = x_train.reshape(-1,1,28,28) # (데이터 개수, 채널 수=1개(흑백), 높이, 너비)\n",
    "x_test = x_test.reshape(-1,1,28,28) \n",
    "\n",
    "\n",
    "for i in range(iters_num):\n",
    "    if i % 100 == 0:\n",
    "        print(f\"epoch {i}\")\n",
    "    batch_mask = np.random.choice(train_size, batch_size)\n",
    "    x_batch = x_train[batch_mask]\n",
    "    t_batch = t_train[batch_mask]\n",
    "\n",
    "    # print(x_batch.shape)\n",
    "    # print(t_batch.shape)\n",
    "\n",
    "    # 오차역전파법으로 기울기를 구한다\n",
    "    grad = network.gradient(x_batch, t_batch)\n",
    "    # print(\"grad[W1]: \",np.count_nonzero(grad['W1']))\n",
    "    # print(\"grad['b1']: \",grad['b1'])\n",
    "    # print(\"grad['W2']: \",grad['W2'])\n",
    "    # print(\"grad['b2']: \",grad['b2'])\n",
    "\n",
    "    # 갱신\n",
    "    for key in ('W1', 'b1', 'W2','b2', 'W3','b3'):\n",
    "        network.params[key] -= learning_rate * grad[key]\n",
    "\n",
    "    loss = network.loss(x_batch, t_batch)\n",
    "    # print(\"loss: \",loss)\n",
    "    train_loss_list.append(loss)\n",
    "\n",
    "    if i % iter_per_epoch == 0:\n",
    "        print(\"loss: \",loss)\n",
    "\n",
    "        # train_acc = network.accuracy(x_train, t_train)\n",
    "        test_acc = network.accuracy(x_test, t_test)\n",
    "        # train_acc_list.append(train_acc)\n",
    "        test_acc_list.append(test_acc)\n",
    "        # print(\"train_acc, test_acc: \", train_acc, test_acc)\n",
    "        print(\"test_acc: \", test_acc)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
