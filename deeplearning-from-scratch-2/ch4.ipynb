{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 4 word2vec 속도 개선\n",
    "## 4.1 word2vec 개선 1\n",
    "### 4.1.2 Embedding 계층 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Embedding:\n",
    "    def __init__(self, W):\n",
    "        self.params = [W]\n",
    "        self.grads = [np.zeros_like(W)]\n",
    "    \n",
    "    def forward(self, idx):\n",
    "        W, = self.params\n",
    "        self.idx = idx\n",
    "        out = W[idx]\n",
    "        return out\n",
    "    \n",
    "    def backward(self, dout):\n",
    "        dW = self.grads\n",
    "        dW[...] = 0\n",
    "\n",
    "        for i, word_id in enumerate(self.idx):\n",
    "            dW[word_id] += dout[i]\n",
    "\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 word2vec 개선 2\n",
    "### 4.2.4 다중 분류에서 이진 분류로 (구현)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingDot:\n",
    "    def __init__(self, W):\n",
    "        self.embed = Embedding(W)\n",
    "        self.params = self.embed.params\n",
    "        self.grads = self.embed.grads\n",
    "        self.cache = None\n",
    "\n",
    "    def forward(self, h, idx):\n",
    "        target_W = self.embed.forward(idx)\n",
    "        out = np.sum(target_W * h, axis=1)\n",
    "\n",
    "        self.cache = (h, target_W)\n",
    "        return out\n",
    "    \n",
    "    def backward(self, dout):\n",
    "        h, target_W = self.cache\n",
    "        dout = dout.reshape(dout.shape[0], 1)\n",
    "\n",
    "        dtarget_W = dout * h\n",
    "        self.embed.backward(dtarget_W)\n",
    "        dh = dout * target_W\n",
    "        return dh\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.7 네거티브 샘플링 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "from common.np import *  # import numpy as np\n",
    "\n",
    "class UnigramSampler:\n",
    "    def __init__(self, corpus, power, sample_size):\n",
    "        self.sample_size = sample_size\n",
    "        self.vocab_size = None\n",
    "        self.word_p = None\n",
    "\n",
    "        counts = collections.Counter()\n",
    "        for word_id in corpus:\n",
    "            counts[word_id] += 1\n",
    "\n",
    "        vocab_size = len(counts)\n",
    "        self.vocab_size = vocab_size\n",
    "\n",
    "        self.word_p = np.zeros(vocab_size)\n",
    "        for i in range(vocab_size):\n",
    "            self.word_p[i] = counts[i]\n",
    "\n",
    "        self.word_p = np.power(self.word_p, power)\n",
    "        self.word_p /= np.sum(self.word_p)\n",
    "\n",
    "    def get_negative_sample(self, target):\n",
    "        batch_size = target.shape[0]\n",
    "\n",
    "        if not GPU:\n",
    "            negative_sample = np.zeros((batch_size, self.sample_size), dtype=np.int32)\n",
    "\n",
    "            for i in range(batch_size):\n",
    "                p = self.word_p.copy()\n",
    "                target_idx = target[i]\n",
    "                p[target_idx] = 0\n",
    "                p /= p.sum()\n",
    "                negative_sample[i, :] = np.random.choice(self.vocab_size, size=self.sample_size, replace=False, p=p)\n",
    "        else:\n",
    "            # GPU(cupy）로 계산할 때는 속도를 우선한다.\n",
    "            # 부정적 예에 타깃이 포함될 수 있다.\n",
    "            negative_sample = np.random.choice(self.vocab_size, size=(batch_size, self.sample_size),\n",
    "                                               replace=True, p=self.word_p)\n",
    "\n",
    "        return negative_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from common.layers import Embedding, SigmoidWithLoss\n",
    "\n",
    "class NegativeSamplingLoss:\n",
    "    def __init__(self, W, corpus, power=0.75, sample_size=5):\n",
    "        self.sample_size = sample_size\n",
    "        self.sampler = UnigramSampler(corpus, power, sample_size)\n",
    "        self.loss_layers = [SigmoidWithLoss() for _ in range(sample_size +1)]\n",
    "        self.embed_dot_layers = [EmbeddingDot(W) for _ in range(sample_size +1)]\n",
    "        self.params, self.grads = [], []\n",
    "        for layer in self.embed_dot_layers:\n",
    "            self.params += layer.params\n",
    "            self.grads += layer.grads\n",
    "\n",
    "    \n",
    "    def forward(self, h, target):\n",
    "        batch_size = target.shape[0]\n",
    "        negative_sample = self.sampler.get_negative_sample(target)\n",
    "\n",
    "        # 긍정적 예 순전파\n",
    "        score = self.embed_dot_layers[0].forward(h, target)\n",
    "        correct_label = np.zeros(batch_size, dtype=np.int32)\n",
    "        loss = self.loss_layers[0].forward(score, correct_label)\n",
    "\n",
    "        # 부정적 예 순전파\n",
    "        negative_label = np.zeros(batch_size, dtype=np.int32)\n",
    "        for i in range(self.sample_size):\n",
    "            negative_target = negative_sample[:, i]\n",
    "            score = self.embed_dot_layers[1 + i].forward(h, negative_target)\n",
    "            loss += self.loss_layers[1 + i].forward(score, negative_label)\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "\n",
    "    def backward(self, dout = 1):\n",
    "        dh = 0 \n",
    "        for l0, l1 in zip(self.loss_layers, self.embed_dot_layers):\n",
    "            dscore = l0.backward(dout)\n",
    "            dh += l1.backward(dscore)\n",
    "\n",
    "        return dh\n",
    "    \n",
    "    \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.1 CBOW 모델 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from common.np import *  # import numpy as np\n",
    "from common.layers import Embedding\n",
    "\n",
    "\n",
    "class CBOW:\n",
    "    def __init__(self, vocab_size, hidden_size, window_size, corpus):\n",
    "        V, H = vocab_size, hidden_size\n",
    "\n",
    "        # 가중치 초기화\n",
    "        W_in = 0.01 * np.random.randn(V, H).astype('f')\n",
    "        W_out = 0.01 * np.random.randn(V, H).astype('f')\n",
    "\n",
    "        # 계층 생성\n",
    "        self.in_layers = []\n",
    "        for i in range(2 * window_size):\n",
    "            layer = Embedding(W_in)  # Embedding 계층 사용\n",
    "            self.in_layers.append(layer)\n",
    "        self.ns_loss = NegativeSamplingLoss(W_out, corpus, power=0.75, sample_size=5)\n",
    "\n",
    "        # 모든 가중치와 기울기를 배열에 모은다.\n",
    "        layers = self.in_layers + [self.ns_loss]\n",
    "        self.params, self.grads = [], []\n",
    "        for layer in layers:\n",
    "            self.params += layer.params\n",
    "            self.grads += layer.grads\n",
    "\n",
    "        # 인스턴스 변수에 단어의 분산 표현을 저장한다.\n",
    "        self.word_vecs = W_in\n",
    "\n",
    "    def forward(self, contexts, target):\n",
    "        h = 0\n",
    "        for i, layer in enumerate(self.in_layers):\n",
    "            h += layer.forward(contexts[:, i])\n",
    "        h *= 1 / len(self.in_layers)\n",
    "        loss = self.ns_loss.forward(h, target)\n",
    "        return loss\n",
    "\n",
    "    def backward(self, dout=1):\n",
    "        dout = self.ns_loss.backward(dout)\n",
    "        dout *= 1 / len(self.in_layers)\n",
    "        for layer in self.in_layers:\n",
    "            layer.backward(dout)\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.2 CBOW 모델 학습 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| 에폭 1 |  반복 1 / 9295 | 시간 0[s] | 손실 4.16\n",
      "| 에폭 1 |  반복 21 / 9295 | 시간 1[s] | 손실 4.16\n",
      "| 에폭 1 |  반복 41 / 9295 | 시간 2[s] | 손실 4.12\n",
      "| 에폭 1 |  반복 61 / 9295 | 시간 3[s] | 손실 3.97\n",
      "| 에폭 1 |  반복 81 / 9295 | 시간 4[s] | 손실 3.68\n",
      "| 에폭 1 |  반복 101 / 9295 | 시간 5[s] | 손실 3.29\n",
      "| 에폭 1 |  반복 121 / 9295 | 시간 6[s] | 손실 2.86\n",
      "| 에폭 1 |  반복 141 / 9295 | 시간 7[s] | 손실 2.45\n",
      "| 에폭 1 |  반복 161 / 9295 | 시간 8[s] | 손실 2.10\n",
      "| 에폭 1 |  반복 181 / 9295 | 시간 9[s] | 손실 1.81\n",
      "| 에폭 1 |  반복 201 / 9295 | 시간 10[s] | 손실 1.55\n",
      "| 에폭 1 |  반복 221 / 9295 | 시간 11[s] | 손실 1.36\n",
      "| 에폭 1 |  반복 241 / 9295 | 시간 12[s] | 손실 1.18\n",
      "| 에폭 1 |  반복 261 / 9295 | 시간 13[s] | 손실 1.05\n",
      "| 에폭 1 |  반복 281 / 9295 | 시간 14[s] | 손실 0.92\n",
      "| 에폭 1 |  반복 301 / 9295 | 시간 15[s] | 손실 0.83\n",
      "| 에폭 1 |  반복 321 / 9295 | 시간 16[s] | 손실 0.75\n",
      "| 에폭 1 |  반복 341 / 9295 | 시간 17[s] | 손실 0.66\n",
      "| 에폭 1 |  반복 361 / 9295 | 시간 18[s] | 손실 0.61\n",
      "| 에폭 1 |  반복 381 / 9295 | 시간 19[s] | 손실 0.54\n",
      "| 에폭 1 |  반복 401 / 9295 | 시간 20[s] | 손실 0.49\n",
      "| 에폭 1 |  반복 421 / 9295 | 시간 21[s] | 손실 0.44\n",
      "| 에폭 1 |  반복 441 / 9295 | 시간 22[s] | 손실 0.41\n",
      "| 에폭 1 |  반복 461 / 9295 | 시간 23[s] | 손실 0.36\n",
      "| 에폭 1 |  반복 481 / 9295 | 시간 24[s] | 손실 0.35\n",
      "| 에폭 1 |  반복 501 / 9295 | 시간 25[s] | 손실 0.31\n",
      "| 에폭 1 |  반복 521 / 9295 | 시간 26[s] | 손실 0.29\n",
      "| 에폭 1 |  반복 541 / 9295 | 시간 27[s] | 손실 0.27\n",
      "| 에폭 1 |  반복 561 / 9295 | 시간 28[s] | 손실 0.24\n",
      "| 에폭 1 |  반복 581 / 9295 | 시간 29[s] | 손실 0.23\n",
      "| 에폭 1 |  반복 601 / 9295 | 시간 30[s] | 손실 0.21\n",
      "| 에폭 1 |  반복 621 / 9295 | 시간 32[s] | 손실 0.19\n",
      "| 에폭 1 |  반복 641 / 9295 | 시간 33[s] | 손실 0.18\n",
      "| 에폭 1 |  반복 661 / 9295 | 시간 35[s] | 손실 0.17\n",
      "| 에폭 1 |  반복 681 / 9295 | 시간 36[s] | 손실 0.16\n",
      "| 에폭 1 |  반복 701 / 9295 | 시간 37[s] | 손실 0.14\n",
      "| 에폭 1 |  반복 721 / 9295 | 시간 39[s] | 손실 0.13\n",
      "| 에폭 1 |  반복 741 / 9295 | 시간 40[s] | 손실 0.13\n",
      "| 에폭 1 |  반복 761 / 9295 | 시간 41[s] | 손실 0.12\n",
      "| 에폭 1 |  반복 781 / 9295 | 시간 43[s] | 손실 0.11\n",
      "| 에폭 1 |  반복 801 / 9295 | 시간 44[s] | 손실 0.11\n",
      "| 에폭 1 |  반복 821 / 9295 | 시간 46[s] | 손실 0.10\n",
      "| 에폭 1 |  반복 841 / 9295 | 시간 47[s] | 손실 0.09\n",
      "| 에폭 1 |  반복 861 / 9295 | 시간 48[s] | 손실 0.09\n",
      "| 에폭 1 |  반복 881 / 9295 | 시간 50[s] | 손실 0.09\n",
      "| 에폭 1 |  반복 901 / 9295 | 시간 52[s] | 손실 0.08\n",
      "| 에폭 1 |  반복 921 / 9295 | 시간 54[s] | 손실 0.08\n",
      "| 에폭 1 |  반복 941 / 9295 | 시간 56[s] | 손실 0.08\n",
      "| 에폭 1 |  반복 961 / 9295 | 시간 57[s] | 손실 0.07\n",
      "| 에폭 1 |  반복 981 / 9295 | 시간 58[s] | 손실 0.06\n",
      "| 에폭 1 |  반복 1001 / 9295 | 시간 59[s] | 손실 0.06\n",
      "| 에폭 1 |  반복 1021 / 9295 | 시간 60[s] | 손실 0.06\n",
      "| 에폭 1 |  반복 1041 / 9295 | 시간 61[s] | 손실 0.06\n",
      "| 에폭 1 |  반복 1061 / 9295 | 시간 63[s] | 손실 0.06\n",
      "| 에폭 1 |  반복 1081 / 9295 | 시간 64[s] | 손실 0.05\n",
      "| 에폭 1 |  반복 1101 / 9295 | 시간 66[s] | 손실 0.05\n",
      "| 에폭 1 |  반복 1121 / 9295 | 시간 67[s] | 손실 0.05\n",
      "| 에폭 1 |  반복 1141 / 9295 | 시간 69[s] | 손실 0.05\n",
      "| 에폭 1 |  반복 1161 / 9295 | 시간 70[s] | 손실 0.05\n",
      "| 에폭 1 |  반복 1181 / 9295 | 시간 72[s] | 손실 0.04\n",
      "| 에폭 1 |  반복 1201 / 9295 | 시간 73[s] | 손실 0.04\n",
      "| 에폭 1 |  반복 1221 / 9295 | 시간 75[s] | 손실 0.04\n",
      "| 에폭 1 |  반복 1241 / 9295 | 시간 76[s] | 손실 0.04\n",
      "| 에폭 1 |  반복 1261 / 9295 | 시간 77[s] | 손실 0.04\n",
      "| 에폭 1 |  반복 1281 / 9295 | 시간 79[s] | 손실 0.04\n",
      "| 에폭 1 |  반복 1301 / 9295 | 시간 80[s] | 손실 0.03\n",
      "| 에폭 1 |  반복 1321 / 9295 | 시간 81[s] | 손실 0.03\n",
      "| 에폭 1 |  반복 1341 / 9295 | 시간 83[s] | 손실 0.03\n",
      "| 에폭 1 |  반복 1361 / 9295 | 시간 84[s] | 손실 0.03\n",
      "| 에폭 1 |  반복 1381 / 9295 | 시간 86[s] | 손실 0.03\n",
      "| 에폭 1 |  반복 1401 / 9295 | 시간 88[s] | 손실 0.03\n",
      "| 에폭 1 |  반복 1421 / 9295 | 시간 89[s] | 손실 0.03\n",
      "| 에폭 1 |  반복 1441 / 9295 | 시간 91[s] | 손실 0.03\n",
      "| 에폭 1 |  반복 1461 / 9295 | 시간 93[s] | 손실 0.03\n",
      "| 에폭 1 |  반복 1481 / 9295 | 시간 94[s] | 손실 0.03\n",
      "| 에폭 1 |  반복 1501 / 9295 | 시간 95[s] | 손실 0.02\n",
      "| 에폭 1 |  반복 1521 / 9295 | 시간 97[s] | 손실 0.02\n",
      "| 에폭 1 |  반복 1541 / 9295 | 시간 98[s] | 손실 0.02\n",
      "| 에폭 1 |  반복 1561 / 9295 | 시간 100[s] | 손실 0.02\n",
      "| 에폭 1 |  반복 1581 / 9295 | 시간 101[s] | 손실 0.02\n",
      "| 에폭 1 |  반복 1601 / 9295 | 시간 102[s] | 손실 0.02\n",
      "| 에폭 1 |  반복 1621 / 9295 | 시간 105[s] | 손실 0.02\n",
      "| 에폭 1 |  반복 1641 / 9295 | 시간 106[s] | 손실 0.02\n",
      "| 에폭 1 |  반복 1661 / 9295 | 시간 108[s] | 손실 0.02\n",
      "| 에폭 1 |  반복 1681 / 9295 | 시간 109[s] | 손실 0.02\n",
      "| 에폭 1 |  반복 1701 / 9295 | 시간 110[s] | 손실 0.02\n",
      "| 에폭 1 |  반복 1721 / 9295 | 시간 112[s] | 손실 0.02\n",
      "| 에폭 1 |  반복 1741 / 9295 | 시간 113[s] | 손실 0.02\n",
      "| 에폭 1 |  반복 1761 / 9295 | 시간 114[s] | 손실 0.02\n",
      "| 에폭 1 |  반복 1781 / 9295 | 시간 116[s] | 손실 0.02\n",
      "| 에폭 1 |  반복 1801 / 9295 | 시간 118[s] | 손실 0.02\n",
      "| 에폭 1 |  반복 1821 / 9295 | 시간 120[s] | 손실 0.01\n",
      "| 에폭 1 |  반복 1841 / 9295 | 시간 121[s] | 손실 0.01\n",
      "| 에폭 1 |  반복 1861 / 9295 | 시간 123[s] | 손실 0.02\n",
      "| 에폭 1 |  반복 1881 / 9295 | 시간 124[s] | 손실 0.02\n",
      "| 에폭 1 |  반복 1901 / 9295 | 시간 126[s] | 손실 0.01\n",
      "| 에폭 1 |  반복 1921 / 9295 | 시간 127[s] | 손실 0.01\n",
      "| 에폭 1 |  반복 1941 / 9295 | 시간 129[s] | 손실 0.01\n",
      "| 에폭 1 |  반복 1961 / 9295 | 시간 130[s] | 손실 0.01\n",
      "| 에폭 1 |  반복 1981 / 9295 | 시간 132[s] | 손실 0.01\n",
      "| 에폭 1 |  반복 2001 / 9295 | 시간 133[s] | 손실 0.01\n",
      "| 에폭 1 |  반복 2021 / 9295 | 시간 135[s] | 손실 0.01\n",
      "| 에폭 1 |  반복 2041 / 9295 | 시간 136[s] | 손실 0.01\n",
      "| 에폭 1 |  반복 2061 / 9295 | 시간 138[s] | 손실 0.01\n",
      "| 에폭 1 |  반복 2081 / 9295 | 시간 139[s] | 손실 0.01\n",
      "| 에폭 1 |  반복 2101 / 9295 | 시간 140[s] | 손실 0.01\n",
      "| 에폭 1 |  반복 2121 / 9295 | 시간 142[s] | 손실 0.01\n",
      "| 에폭 1 |  반복 2141 / 9295 | 시간 143[s] | 손실 0.01\n",
      "| 에폭 1 |  반복 2161 / 9295 | 시간 145[s] | 손실 0.01\n",
      "| 에폭 1 |  반복 2181 / 9295 | 시간 146[s] | 손실 0.01\n",
      "| 에폭 1 |  반복 2201 / 9295 | 시간 148[s] | 손실 0.01\n",
      "| 에폭 1 |  반복 2221 / 9295 | 시간 149[s] | 손실 0.01\n",
      "| 에폭 1 |  반복 2241 / 9295 | 시간 150[s] | 손실 0.01\n",
      "| 에폭 1 |  반복 2261 / 9295 | 시간 152[s] | 손실 0.01\n",
      "| 에폭 1 |  반복 2281 / 9295 | 시간 154[s] | 손실 0.01\n",
      "| 에폭 1 |  반복 2301 / 9295 | 시간 156[s] | 손실 0.01\n",
      "| 에폭 1 |  반복 2321 / 9295 | 시간 158[s] | 손실 0.01\n",
      "| 에폭 1 |  반복 2341 / 9295 | 시간 159[s] | 손실 0.01\n",
      "| 에폭 1 |  반복 2361 / 9295 | 시간 161[s] | 손실 0.01\n",
      "| 에폭 1 |  반복 2381 / 9295 | 시간 163[s] | 손실 0.01\n",
      "| 에폭 1 |  반복 2401 / 9295 | 시간 165[s] | 손실 0.01\n",
      "| 에폭 1 |  반복 2421 / 9295 | 시간 167[s] | 손실 0.01\n",
      "| 에폭 1 |  반복 2441 / 9295 | 시간 168[s] | 손실 0.01\n",
      "| 에폭 1 |  반복 2461 / 9295 | 시간 170[s] | 손실 0.01\n",
      "| 에폭 1 |  반복 2481 / 9295 | 시간 171[s] | 손실 0.01\n",
      "| 에폭 1 |  반복 2501 / 9295 | 시간 173[s] | 손실 0.01\n",
      "| 에폭 1 |  반복 2521 / 9295 | 시간 174[s] | 손실 0.01\n",
      "| 에폭 1 |  반복 2541 / 9295 | 시간 176[s] | 손실 0.01\n",
      "| 에폭 1 |  반복 2561 / 9295 | 시간 177[s] | 손실 0.01\n",
      "| 에폭 1 |  반복 2581 / 9295 | 시간 178[s] | 손실 0.01\n",
      "| 에폭 1 |  반복 2601 / 9295 | 시간 179[s] | 손실 0.01\n",
      "| 에폭 1 |  반복 2621 / 9295 | 시간 181[s] | 손실 0.01\n",
      "| 에폭 1 |  반복 2641 / 9295 | 시간 182[s] | 손실 0.01\n",
      "| 에폭 1 |  반복 2661 / 9295 | 시간 184[s] | 손실 0.01\n",
      "| 에폭 1 |  반복 2681 / 9295 | 시간 185[s] | 손실 0.01\n",
      "| 에폭 1 |  반복 2701 / 9295 | 시간 187[s] | 손실 0.01\n",
      "| 에폭 1 |  반복 2721 / 9295 | 시간 188[s] | 손실 0.01\n",
      "| 에폭 1 |  반복 2741 / 9295 | 시간 189[s] | 손실 0.01\n",
      "| 에폭 1 |  반복 2761 / 9295 | 시간 190[s] | 손실 0.01\n",
      "| 에폭 1 |  반복 2781 / 9295 | 시간 191[s] | 손실 0.01\n",
      "| 에폭 1 |  반복 2801 / 9295 | 시간 192[s] | 손실 0.01\n",
      "| 에폭 1 |  반복 2821 / 9295 | 시간 194[s] | 손실 0.01\n",
      "| 에폭 1 |  반복 2841 / 9295 | 시간 195[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 2861 / 9295 | 시간 196[s] | 손실 0.01\n",
      "| 에폭 1 |  반복 2881 / 9295 | 시간 197[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 2901 / 9295 | 시간 198[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 2921 / 9295 | 시간 200[s] | 손실 0.01\n",
      "| 에폭 1 |  반복 2941 / 9295 | 시간 201[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 2961 / 9295 | 시간 202[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 2981 / 9295 | 시간 203[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 3001 / 9295 | 시간 205[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 3021 / 9295 | 시간 206[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 3041 / 9295 | 시간 207[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 3061 / 9295 | 시간 209[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 3081 / 9295 | 시간 210[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 3101 / 9295 | 시간 211[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 3121 / 9295 | 시간 212[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 3141 / 9295 | 시간 214[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 3161 / 9295 | 시간 215[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 3181 / 9295 | 시간 216[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 3201 / 9295 | 시간 218[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 3221 / 9295 | 시간 219[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 3241 / 9295 | 시간 220[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 3261 / 9295 | 시간 221[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 3281 / 9295 | 시간 222[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 3301 / 9295 | 시간 224[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 3321 / 9295 | 시간 225[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 3341 / 9295 | 시간 226[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 3361 / 9295 | 시간 227[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 3381 / 9295 | 시간 228[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 3401 / 9295 | 시간 230[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 3421 / 9295 | 시간 231[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 3441 / 9295 | 시간 232[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 3461 / 9295 | 시간 234[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 3481 / 9295 | 시간 235[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 3501 / 9295 | 시간 236[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 3521 / 9295 | 시간 237[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 3541 / 9295 | 시간 238[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 3561 / 9295 | 시간 240[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 3581 / 9295 | 시간 241[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 3601 / 9295 | 시간 242[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 3621 / 9295 | 시간 243[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 3641 / 9295 | 시간 244[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 3661 / 9295 | 시간 245[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 3681 / 9295 | 시간 246[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 3701 / 9295 | 시간 247[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 3721 / 9295 | 시간 248[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 3741 / 9295 | 시간 249[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 3761 / 9295 | 시간 251[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 3781 / 9295 | 시간 252[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 3801 / 9295 | 시간 253[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 3821 / 9295 | 시간 254[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 3841 / 9295 | 시간 255[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 3861 / 9295 | 시간 256[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 3881 / 9295 | 시간 258[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 3901 / 9295 | 시간 259[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 3921 / 9295 | 시간 261[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 3941 / 9295 | 시간 262[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 3961 / 9295 | 시간 264[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 3981 / 9295 | 시간 266[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 4001 / 9295 | 시간 267[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 4021 / 9295 | 시간 269[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 4041 / 9295 | 시간 270[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 4061 / 9295 | 시간 272[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 4081 / 9295 | 시간 273[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 4101 / 9295 | 시간 275[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 4121 / 9295 | 시간 276[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 4141 / 9295 | 시간 278[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 4161 / 9295 | 시간 279[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 4181 / 9295 | 시간 281[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 4201 / 9295 | 시간 282[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 4221 / 9295 | 시간 283[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 4241 / 9295 | 시간 284[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 4261 / 9295 | 시간 285[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 4281 / 9295 | 시간 286[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 4301 / 9295 | 시간 288[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 4321 / 9295 | 시간 289[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 4341 / 9295 | 시간 290[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 4361 / 9295 | 시간 292[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 4381 / 9295 | 시간 294[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 4401 / 9295 | 시간 295[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 4421 / 9295 | 시간 296[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 4441 / 9295 | 시간 298[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 4461 / 9295 | 시간 299[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 4481 / 9295 | 시간 301[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 4501 / 9295 | 시간 303[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 4521 / 9295 | 시간 304[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 4541 / 9295 | 시간 305[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 4561 / 9295 | 시간 307[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 4581 / 9295 | 시간 308[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 4601 / 9295 | 시간 310[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 4621 / 9295 | 시간 311[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 4641 / 9295 | 시간 313[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 4661 / 9295 | 시간 314[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 4681 / 9295 | 시간 316[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 4701 / 9295 | 시간 317[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 4721 / 9295 | 시간 318[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 4741 / 9295 | 시간 319[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 4761 / 9295 | 시간 320[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 4781 / 9295 | 시간 322[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 4801 / 9295 | 시간 323[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 4821 / 9295 | 시간 324[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 4841 / 9295 | 시간 325[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 4861 / 9295 | 시간 327[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 4881 / 9295 | 시간 328[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 4901 / 9295 | 시간 329[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 4921 / 9295 | 시간 331[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 4941 / 9295 | 시간 332[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 4961 / 9295 | 시간 334[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 4981 / 9295 | 시간 335[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 5001 / 9295 | 시간 336[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 5021 / 9295 | 시간 337[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 5041 / 9295 | 시간 338[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 5061 / 9295 | 시간 339[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 5081 / 9295 | 시간 340[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 5101 / 9295 | 시간 341[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 5121 / 9295 | 시간 342[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 5141 / 9295 | 시간 343[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 5161 / 9295 | 시간 345[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 5181 / 9295 | 시간 346[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 5201 / 9295 | 시간 347[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 5221 / 9295 | 시간 348[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 5241 / 9295 | 시간 350[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 5261 / 9295 | 시간 351[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 5281 / 9295 | 시간 352[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 5301 / 9295 | 시간 354[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 5321 / 9295 | 시간 355[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 5341 / 9295 | 시간 356[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 5361 / 9295 | 시간 357[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 5381 / 9295 | 시간 358[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 5401 / 9295 | 시간 359[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 5421 / 9295 | 시간 360[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 5441 / 9295 | 시간 361[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 5461 / 9295 | 시간 362[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 5481 / 9295 | 시간 363[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 5501 / 9295 | 시간 364[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 5521 / 9295 | 시간 366[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 5541 / 9295 | 시간 367[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 5561 / 9295 | 시간 368[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 5581 / 9295 | 시간 369[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 5601 / 9295 | 시간 371[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 5621 / 9295 | 시간 372[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 5641 / 9295 | 시간 373[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 5661 / 9295 | 시간 374[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 5681 / 9295 | 시간 376[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 5701 / 9295 | 시간 377[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 5721 / 9295 | 시간 378[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 5741 / 9295 | 시간 379[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 5761 / 9295 | 시간 380[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 5781 / 9295 | 시간 381[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 5801 / 9295 | 시간 382[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 5821 / 9295 | 시간 383[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 5841 / 9295 | 시간 384[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 5861 / 9295 | 시간 385[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 5881 / 9295 | 시간 386[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 5901 / 9295 | 시간 388[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 5921 / 9295 | 시간 389[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 5941 / 9295 | 시간 390[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 5961 / 9295 | 시간 391[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 5981 / 9295 | 시간 392[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 6001 / 9295 | 시간 393[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 6021 / 9295 | 시간 394[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 6041 / 9295 | 시간 395[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 6061 / 9295 | 시간 396[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 6081 / 9295 | 시간 397[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 6101 / 9295 | 시간 398[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 6121 / 9295 | 시간 399[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 6141 / 9295 | 시간 400[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 6161 / 9295 | 시간 401[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 6181 / 9295 | 시간 402[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 6201 / 9295 | 시간 403[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 6221 / 9295 | 시간 404[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 6241 / 9295 | 시간 405[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 6261 / 9295 | 시간 406[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 6281 / 9295 | 시간 408[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 6301 / 9295 | 시간 409[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 6321 / 9295 | 시간 410[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 6341 / 9295 | 시간 412[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 6361 / 9295 | 시간 413[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 6381 / 9295 | 시간 415[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 6401 / 9295 | 시간 416[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 6421 / 9295 | 시간 418[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 6441 / 9295 | 시간 419[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 6461 / 9295 | 시간 420[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 6481 / 9295 | 시간 422[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 6501 / 9295 | 시간 423[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 6521 / 9295 | 시간 425[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 6541 / 9295 | 시간 426[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 6561 / 9295 | 시간 427[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 6581 / 9295 | 시간 428[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 6601 / 9295 | 시간 429[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 6621 / 9295 | 시간 430[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 6641 / 9295 | 시간 431[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 6661 / 9295 | 시간 433[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 6681 / 9295 | 시간 434[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 6701 / 9295 | 시간 435[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 6721 / 9295 | 시간 437[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 6741 / 9295 | 시간 439[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 6761 / 9295 | 시간 440[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 6781 / 9295 | 시간 442[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 6801 / 9295 | 시간 443[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 6821 / 9295 | 시간 444[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 6841 / 9295 | 시간 446[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 6861 / 9295 | 시간 447[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 6881 / 9295 | 시간 448[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 6901 / 9295 | 시간 450[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 6921 / 9295 | 시간 451[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 6941 / 9295 | 시간 452[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 6961 / 9295 | 시간 453[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 6981 / 9295 | 시간 455[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 7001 / 9295 | 시간 457[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 7021 / 9295 | 시간 459[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 7041 / 9295 | 시간 460[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 7061 / 9295 | 시간 462[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 7081 / 9295 | 시간 464[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 7101 / 9295 | 시간 465[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 7121 / 9295 | 시간 467[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 7141 / 9295 | 시간 468[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 7161 / 9295 | 시간 470[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 7181 / 9295 | 시간 472[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 7201 / 9295 | 시간 474[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 7221 / 9295 | 시간 476[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 7241 / 9295 | 시간 477[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 7261 / 9295 | 시간 479[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 7281 / 9295 | 시간 480[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 7301 / 9295 | 시간 482[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 7321 / 9295 | 시간 483[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 7341 / 9295 | 시간 484[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 7361 / 9295 | 시간 486[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 7381 / 9295 | 시간 487[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 7401 / 9295 | 시간 488[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 7421 / 9295 | 시간 489[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 7441 / 9295 | 시간 490[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 7461 / 9295 | 시간 492[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 7481 / 9295 | 시간 493[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 7501 / 9295 | 시간 495[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 7521 / 9295 | 시간 497[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 7541 / 9295 | 시간 498[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 7561 / 9295 | 시간 500[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 7581 / 9295 | 시간 502[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 7601 / 9295 | 시간 503[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 7621 / 9295 | 시간 505[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 7641 / 9295 | 시간 507[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 7661 / 9295 | 시간 508[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 7681 / 9295 | 시간 510[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 7701 / 9295 | 시간 512[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 7721 / 9295 | 시간 514[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 7741 / 9295 | 시간 516[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 7761 / 9295 | 시간 517[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 7781 / 9295 | 시간 519[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 7801 / 9295 | 시간 521[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 7821 / 9295 | 시간 523[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 7841 / 9295 | 시간 525[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 7861 / 9295 | 시간 527[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 7881 / 9295 | 시간 529[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 7901 / 9295 | 시간 530[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 7921 / 9295 | 시간 531[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 7941 / 9295 | 시간 533[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 7961 / 9295 | 시간 535[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 7981 / 9295 | 시간 536[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 8001 / 9295 | 시간 538[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 8021 / 9295 | 시간 541[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 8041 / 9295 | 시간 543[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 8061 / 9295 | 시간 544[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 8081 / 9295 | 시간 546[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 8101 / 9295 | 시간 548[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 8121 / 9295 | 시간 550[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 8141 / 9295 | 시간 552[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 8161 / 9295 | 시간 553[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 8181 / 9295 | 시간 554[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 8201 / 9295 | 시간 556[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 8221 / 9295 | 시간 558[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 8241 / 9295 | 시간 559[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 8261 / 9295 | 시간 560[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 8281 / 9295 | 시간 561[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 8301 / 9295 | 시간 563[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 8321 / 9295 | 시간 564[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 8341 / 9295 | 시간 566[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 8361 / 9295 | 시간 567[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 8381 / 9295 | 시간 569[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 8401 / 9295 | 시간 570[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 8421 / 9295 | 시간 572[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 8441 / 9295 | 시간 573[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 8461 / 9295 | 시간 575[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 8481 / 9295 | 시간 577[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 8501 / 9295 | 시간 578[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 8521 / 9295 | 시간 580[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 8541 / 9295 | 시간 582[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 8561 / 9295 | 시간 583[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 8581 / 9295 | 시간 585[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 8601 / 9295 | 시간 587[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 8621 / 9295 | 시간 588[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 8641 / 9295 | 시간 589[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 8661 / 9295 | 시간 590[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 8681 / 9295 | 시간 592[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 8701 / 9295 | 시간 593[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 8721 / 9295 | 시간 594[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 8741 / 9295 | 시간 595[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 8761 / 9295 | 시간 596[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 8781 / 9295 | 시간 597[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 8801 / 9295 | 시간 599[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 8821 / 9295 | 시간 600[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 8841 / 9295 | 시간 602[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 8861 / 9295 | 시간 603[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 8881 / 9295 | 시간 605[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 8901 / 9295 | 시간 606[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 8921 / 9295 | 시간 607[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 8941 / 9295 | 시간 608[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 8961 / 9295 | 시간 609[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 8981 / 9295 | 시간 611[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 9001 / 9295 | 시간 612[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 9021 / 9295 | 시간 614[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 9041 / 9295 | 시간 615[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 9061 / 9295 | 시간 616[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 9081 / 9295 | 시간 618[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 9101 / 9295 | 시간 619[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 9121 / 9295 | 시간 620[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 9141 / 9295 | 시간 622[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 9161 / 9295 | 시간 624[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 9181 / 9295 | 시간 625[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 9201 / 9295 | 시간 627[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 9221 / 9295 | 시간 628[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 9241 / 9295 | 시간 629[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 9261 / 9295 | 시간 631[s] | 손실 0.00\n",
      "| 에폭 1 |  반복 9281 / 9295 | 시간 632[s] | 손실 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Beom\\deeplearning-from-scratch\\.venv\\Lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 48152 (\\N{HANGUL SYLLABLE BAN}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "c:\\Users\\Beom\\deeplearning-from-scratch\\.venv\\Lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 48373 (\\N{HANGUL SYLLABLE BOG}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "c:\\Users\\Beom\\deeplearning-from-scratch\\.venv\\Lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 49552 (\\N{HANGUL SYLLABLE SON}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "c:\\Users\\Beom\\deeplearning-from-scratch\\.venv\\Lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 49892 (\\N{HANGUL SYLLABLE SIL}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAioAAAGwCAYAAACHJU4LAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAKvJJREFUeJzt3XuQVPWd9/HP6Z7pnvsMw2WGycwoCQoS5CKXyWiexAQUkYcYk6zRh4rGtWJiQDFspZS4MbdawU09W0ZlkY3uulsPiqUlXtiIIaCgKyAMsCIIiwZkBIarc5/p6en+PX803dAMl+7pPuf0MO9XVRcz59L97XOk+Pi7HcsYYwQAAJCBPG4XAAAAcC4EFQAAkLEIKgAAIGMRVAAAQMYiqAAAgIxFUAEAABmLoAIAADJWltsFpCIcDuvgwYMqLCyUZVlulwMAABJgjFFLS4sqKirk8Zy/zaRPB5WDBw+qqqrK7TIAAEAv1NfXq7Ky8rzH9OmgUlhYKCnyRYuKilyuBgAAJKK5uVlVVVWxf8fPp08HlWh3T1FREUEFAIA+JpFhGwymBQAAGYugAgAAMhZBBQAAZCyCCgAAyFgEFQAAkLEIKgAAIGMRVAAAQMYiqAAAgIxFUAEAABmLoAIAADIWQQUAAGQsggoAAMhYBJWz6AyG9N/1jQqFjdulAADQrxFUzmLTvhO6adF/adxv/6yX6j5zuxwAAPotgspZHGkOSJJaOrv1+Oo9MoaWFQAA3EBQOYvvTqjU9l9fL0naf6Jduw+3uFwRAAD9E0HlHApzsjX1iiGSpDc/POxyNQAA9E8ElfP4+uWDJUn//Vmju4UAANBPEVTOo7w4V5J0vDXgciUAAPRPBJXzKM33SZKOt3W5XAkAAP0TQeU8Bp4MKicIKgAAuIKgch6lBZGg0t4VUmcw5HI1AAD0PwSV8yj0Zynba0miVQUAADdkTFBZuHChLMvS/fff73YpMZZlxcapEFQAAHBeRgSVTZs2acmSJRozZozbpfRQmu+XxIBaAADc4HpQaW1t1axZs/THP/5RAwYMcLucHk4NqGWKMgAATnM9qMyePVszZszQ1KlTL3hsIBBQc3Nz3MtusSnKrbSoAADgtCw3P3zZsmXasmWLNm3alNDxCxYs0G9+8xubq4rHGBUAANzjWotKfX295s6dq6VLlyonJyehc+bPn6+mpqbYq76+3uYqWUsFAAA3udaiUldXpyNHjuiqq66KbQuFQlq3bp2efPJJBQIBeb3euHP8fr/8fr+jdRbnZUuSmjqCjn4uAABwMahMmTJF27dvj9t25513auTIkXrggQd6hBS35GZH6uhgwTcAABznWlApLCzU6NGj47bl5+dr4MCBPba7Kc8XuUTtXQQVAACc5vqsn0yX5zvZokJQAQDAca7O+jnT22+/7XYJPeSc7Ppp7+p2uRIAAPofWlQuINqi0hkMu1wJAAD9D0HlAqJBhRYVAACcR1C5gNxYUGGMCgAATiOoXEB0enKgO6xQ2LhcDQAA/QtB5QKi05MlqZO1VAAAcBRB5QJysj2yrMjPdP8AAOAsgsoFWJZ1anVaggoAAI4iqCQgGlTag8z8AQDASQSVBOSyOi0AAK4gqCSAZfQBAHAHQSUBuTyYEAAAVxBUEpCbHblM7UxPBgDAUQSVBETXUumkRQUAAEcRVBKQy/N+AABwBUElAaemJ9OiAgCAkwgqCWDWDwAA7iCoJIB1VAAAcAdBJQF52SenJ9P1AwCAowgqCcj1RS4TLSoAADiLoJIAf1ak66erO+xyJQAA9C8ElQT4syKXKUBQAQDAUQSVBPhiQYWuHwAAnERQSUC064cWFQAAnEVQSQBdPwAAuIOgkgD/yYcSMpgWAABnEVQS4PMyRgUAADcQVBLgP/msn0CQFhUAAJxEUEkAY1QAAHAHQSUBfqYnAwDgCoJKAqJdPwymBQDAWQSVBJwaTBuWMcblagAA6D8IKgmITk+WpK4QrSoAADiFoJKA6BgViQG1AAA4iaCSgGjXj8Q4FQAAnERQSYBlWac9mJCgAgCAUwgqCYpNUQ4yRRkAAKcQVBLEE5QBAHAeQSVBrE4LAIDzCCoJigYVBtMCAOAcgkqCfCyjDwCA4wgqCeIJygAAOI+gkiDGqAAA4DyCSoJiY1RCdP0AAOAUgkqCTq2jQosKAABOIagkiHVUAABwHkElQX5m/QAA4DiCSoL82ayjAgCA0wgqCYo+QZmuHwAAnENQSVBsHRWCCgAAjiGoJIinJwMA4DyCSoJY8A0AAOcRVBIUnZ7MYFoAAJxDUEmQjxYVAAAcR1BJEOuoAADgPIJKgqLrqNCiAgCAcwgqCWIJfQAAnEdQSRALvgEA4DyCSoJiXT+sowIAgGMIKgliejIAAM4jqCSIBd8AAHAeQSVBzPoBAMB5BJUEnRpMyxgVAACcQlBJEE9PBgDAeQSVBEXHqHR1h2WMcbkaAAD6B4JKgqJBRZK6QrSqAADgBIJKgnynBRW6fwAAcAZBJUHRwbSSFAgSVAAAcAJBJUGWZfEEZQAAHEZQSQKLvgEA4CyCShKiU5RZRh8AAGe4GlQWL16sMWPGqKioSEVFRaqtrdUbb7zhZknnxROUAQBwlqtBpbKyUgsXLlRdXZ02b96sb37zm7rpppu0Y8cON8s6J56gDACAs7Lc/PCZM2fG/f4P//APWrx4sTZs2KAvf/nLLlV1btEnKNOiAgCAM1wNKqcLhUJ68cUX1dbWptra2rMeEwgEFAgEYr83Nzc7VZ6k+NVpAQCA/VwfTLt9+3YVFBTI7/frJz/5iZYvX65Ro0ad9dgFCxaouLg49qqqqnK0Vh+zfgAAcJTrQWXEiBHatm2bNm7cqHvuuUd33HGHdu7cedZj58+fr6amptirvr7e0VpZRwUAAGe53vXj8/k0fPhwSdKECRO0adMm/eEPf9CSJUt6HOv3++X3+50u8dTnM0YFAABHud6icqZwOBw3DiWTMOsHAABnudqiMn/+fE2fPl3V1dVqaWnRc889p7fffltvvvmmm2Wdk//kOio8PRkAAGe4GlSOHDmi22+/XYcOHVJxcbHGjBmjN998U9ddd52bZZ3TqRYVggoAAE5wNag888wzbn580hijAgCAszJujEomY9YPAADOIqgkgQXfAABwFkElCSz4BgCAswgqSWCMCgAAziKoJCE264cxKgAAOIKgkgTGqAAA4CyCShIYowIAgLMIKkmIjVFhwTcAABxBUEkC66gAAOAsgkoSmPUDAICzCCpJiM76YTAtAADOIKgkwedlMC0AAE4iqCSBdVQAAHAWQSUJzPoBAMBZBJUkxGb9hAgqAAA4gaCSBN9pK9MaY1yuBgCAix9BJQnRFhWJAbUAADiBoJKE6BgViaACAIATCCpJyPZasqzIz8z8AQDAfgSVJFiWxROUAQBwEEElSSz6BgCAcwgqSfJns5YKAABOIagkiScoAwDgHIJKkhijAgCAcwgqSfJFl9EnqAAAYDuCSpJOdf0QVAAAsBtBJUmMUQEAwDkElSQx6wcAAOcQVJIUG0zLE5QBALAdQSVJ0ScoB4J0/QAAYDeCSpIYTAsAgHMIKknyMz0ZAADHEFSSxIJvAAA4h6CSJKYnAwDgHIJKkhijAgCAcwgqSWIdFQAAnENQSRJdPwAAOIegkiQfC74BAOAYgkqSYi0qdP0AAGA7gkqSWEcFAADnEFSSxBgVAACcQ1BJkj+bBd8AAHAKQSVJPi9dPwAAOIWgkqRoiwpBBQAA+xFUknRq1g9jVAAAsBtBJUnRWT+sowIAgP0IKknysY4KAACOIagkiYcSAgDgHIJKkvynLaEfDhuXqwEA4OJGUElS9OnJEuNUAACwG0ElSdEWFYnuHwAA7EZQSVKWx5JlRX5mGX0AAOxFUEmSZVk8QRkAAIcQVHqBJygDAOAMgkovxGb+EFQAALAVQaUXYou+MUYFAABbEVR6gUXfAABwBkGlFxijAgCAMwgqveDP5gnKAAA4gaDSC6cvow8AAOxDUOkFX7Trh3VUAACwVVYyBweDQRmT+IP4PB6PsrKS+og+gcG0AAA4I6kU8eUvf1mVlZUXDCuWZckYo7a2Nr3//vspFZiJ/ExPBgDAEUkFlfz8fK1Zsybh4ydNmpR0QX1BdNYPC74BAGCvpMaoWNGn8dl0fF/ho+sHAABHMJi2F3JOTk/uYHoyAAC2Iqj0Qm52pOunk6ACAICtCCq9kOeLBJWOLoIKAAB2Smowrc/n09VXX53w8YMGDUq6oL4g52SLCl0/AADYK6mgMnnyZB09ejTh44cPH550QX1Bni9y2dppUQEAwFZJBZV169bptddeS3jRt7/5m7/R7373u3PuX7BggV5++WXt2rVLubm5uvrqq/Xoo49qxIgRyZTluFxfpMeMMSoAANgrqaBiWZaqq6sTPv5CgWbt2rWaPXu2Jk2apO7ubv3iF7/Q9ddfr507dyo/Pz+Z0hyVm02LCgAATkg6qKTz+JUrV8b9/uyzz2rIkCGqq6vT1772tR7HBwIBBQKB2O/Nzc1J1ZMuuQymBQDAERk166epqUmSVFpaetb9CxYsUHFxcexVVVXlZHkxuQymBQDAERkTVMLhsO6//35dc801Gj169FmPmT9/vpqammKv+vp6h6uMYHoyAADOSKrrp6OjQ7/97W8TOjaZpyxL0uzZs/Xhhx/q3XffPecxfr9ffr8/qfe1Q3R6cntXt8uVAABwcUsqqCxZskQdHR0JHz9t2rSEjpszZ45WrFihdevWqbKyMpmSXBFtUekM8qwfAADslFRQOdsA11QYY3Tvvfdq+fLlevvttzVs2LC0vr9domNUukJhdYfCyvJmTA8aAAAXlaSCSrrNnj1bzz33nF599VUVFhaqoaFBklRcXKzc3Fw3Szuv6KwfKTKgtpCgAgCALVz9F3bx4sVqamrStddeq6FDh8ZeL7zwgptlXZA/y6PozGsG1AIAYB9XW1SSHXCbKSzLUl62V21dIaYoAwBgI/oseina/cPqtAAA2Ieg0kux1WlpUQEAwDYElV6KrU5LiwoAALYhqPRSri8yvIegAgCAfQgqvZSbHbl07XT9AABgG4JKL+WdbFHppEUFAADbEFR6KZfn/QAAYDuCSi/FpifT9QMAgG0IKr0UezAhXT8AANiGoNJL0TEqbQQVAABsQ1DppXwfY1QAALAbQaWX8vwnW1QCtKgAAGAXgkovRVtU2gK0qAAAYBeCSi/FWlTo+gEAwDYElV7K5+nJAADYjqDSS7FZP3T9AABgG4JKLxWc7PqhRQUAAPsQVHopz89gWgAA7EZQ6aV836kWFWOMy9UAAHBxIqj0UrRFpTts1BUKu1wNAAAXJ4JKL+WdfHqyJLWz6BsAALYgqPRSltcjf1bk8rGWCgAA9iCopCCfmT8AANiKoJKCPJbRBwDAVgSVFJw+8wcAAKQfQSUFrKUCAIC9CCopoEUFAAB7EVRSEB2j0kqLCgAAtiCopCA664euHwAA7EFQSUFRTiSotHQSVAAAsANBJQVFudmSpKaOoMuVAABwcSKopKCYoAIAgK0IKimItqg0dxJUAACwA0ElBUU5tKgAAGAngkoK6PoBAMBeBJUURINKcwezfgAAsANBJQXFedGgEpQxxuVqAAC4+BBUUhBdR6UrFFZnMOxyNQAAXHwIKiko8GfJ67EkMfMHAAA7EFRSYFlWrFWFAbUAAKQfQSVFrE4LAIB9CCopOjXzh6ACAEC6EVRSxFoqAADYh6CSIlanBQDAPgSVFDFGBQAA+xBUUsTqtAAA2IegkqKiXKYnAwBgF4JKihhMCwCAfQgqKYp1/bAyLQAAaUdQSRHrqAAAYB+CSoqYngwAgH0IKimiRQUAAPsQVFIUDSptXSEFQ2GXqwEA4OJCUElR4cmnJ0u0qgAAkG4ElRRleT0q8EfCSnMni74BAJBOBJU0YC0VAADsQVBJg2j3D0EFAID0IqikATN/AACwB0ElDUryIkGlsb3L5UoAALi4EFTSYGCBX5J0rJWgAgBAOhFU0mDQyaBytDXgciUAAFxcCCppMLjAJ0k61kJQAQAgnQgqaTC4MNr1Q1ABACCdCCppMIgxKgAA2IKgkgaxMSp0/QAAkFYElTQYdLLrpyMYUluAZfQBAEgXgkoa5Pu8ys32SmKcCgAA6URQSQPLsjSo8OTMH4IKAABpQ1BJk1PjVBhQCwBAuhBU0oRF3wAASD9Xg8q6des0c+ZMVVRUyLIsvfLKK26Wk5LYWirM/AEAIG1cDSptbW0aO3asFi1a5GYZaXFqLRWCCgAA6ZLl5odPnz5d06dPT/j4QCCgQOBUEGhubrajrF6JLaNPUAEAIG361BiVBQsWqLi4OPaqqqpyu6QYFn0DACD9+lRQmT9/vpqammKv+vp6t0uKOfW8H2b9AACQLq52/STL7/fL7/e7XcZZMUYFAID061MtKpksuox+exfL6AMAkC4ElTTJ93mVkx25nLSqAACQHq52/bS2turjjz+O/b53715t27ZNpaWlqq6udrGy5FmWpcGFftWf6NCx1oAuGZjvdkkAAPR5rraobN68WePHj9f48eMlSfPmzdP48eP18MMPu1lWrzHzBwCA9HK1ReXaa6+VMcbNEtKqoiRXW/c36rPPO9wuBQCAiwJjVNLo0oF5kqR9x9tcrgQAgIsDQSWNouNSPj3e7nIlAABcHAgqaXTpyaBCiwoAAOlBUEmjSwdFun4OfN6hru6wy9UAAND3EVTSaHCBX3k+r8JG+uxzun8AAEgVQSWNLMuKjVOh+wcAgNQRVNIsNvPnGC0qAACkiqCSZqdm/tCiAgBAqggqaXZqLRVaVAAASBVBJc1oUQEAIH0IKmk2bFAkqHz2eYeCIaYoAwCQCoJKmg0p9Csn26PusNHBRp75AwBAKggqaebxWLqkNNKqsvcY3T8AAKSCoGKD6pMDautPMKAWAIBUEFRsUF0aCSo8nBAAgNQQVGxwyckWlf20qAAAkBKCig2qSgkqAACkA0HFBpecFlSMMS5XAwBA30VQsUHlgDxZltTeFdKx1i63ywEAoM8iqNjAl+VRRXGuJJ6iDABAKggqNhlVUSRJ2rzvc5crAQCg7yKo2OQrXxwoSdrw1+MuVwIAQN9FULFJ7cmgsmnfCZ75AwBALxFUbDKyvFAledlq7wrpwwNNbpcDAECfRFCxicdj6covFEuSPjrU4nI1AAD0TQQVG40aGhlQu6uh2eVKAADomwgqNho5tFCStIsWFQAAeoWgYqOR5ZEWlY8amlmhFgCAXiCo2OhLgwuU7bXU0tmtzz7vcLscAAD6HIKKjXxZHo0oj3T/bK1vdLcYAAD6IIKKzSZfGllP5f29LPwGAECyCCo2mzysVJK08a8nXK4EAIC+h6Bis2hQ2XOkVcdbAy5XAwBA30JQsVlpvk+XlxVIkjbxgEIAAJJCUHFAzbDIOJWNjFMBACApBBUHRLt/3t/LOBUAAJJBUHFAzcmgsvNQs5ragy5XAwBA30FQccCQohxdXlYgY6S/fHTY7XIAAOgzCCoOmXFlhSTp9Q8OulwJAAB9B0HFIf977FBJ0rt7jtH9AwBAgggqDvnS4AJ9aXC+usNG6/96zO1yAADoEwgqDvpflw2WJL37MUEFAIBEEFQcdM3wQZKk//qY9VQAAEgEQcVBNV8sVZbH0t5jbXp12wG3ywEAIOMRVBxUlJOte679kiTpFy9vV0sng2oBADgfgorD7p96uS4ZmKe2rhBdQAAAXABBxWFej6VvjBgiSVr7P0dcrgYAgMxGUHHBN0ZGgspbu46qOxR2uRoAADIXQcUFNcNKVZKXrYbmTv3xnb1ulwMAQMYiqLggJ9urv58xSpL02F/+RwcaO1yuCACAzERQccl3r/qCJg8rVaA7rP/75m63ywEAICMRVFxiWZYeuvEKSdLLWw/owwNNLlcEAEDmIai4aGxViW4aF3mq8m9f36lQ2LhcEQAAmYWg4rKfTxuhnGyP3t93Qo+v3uN2OQAAZBSCissqB+TpkZuvlCQ9+dbH2nGQLiAAAKIIKhngO1dVasaVQxUKG/39Kx/KGLqAAACQCCoZ4+GZo5Tn82rr/kYt3bjf7XIAAMgIBJUMUVaUox9/LfLAwr9/5UPNXbZVYQbXAgD6OYJKBvnR14ZpxpihkqRXtx3UI3/6SEGW2AcA9GMElQyS58vSov9zlRZ+JzK49ul39+qe/7eFMSsAgH6LoJKBbp1crce+P04+r0d/+eiwXthU73ZJAAC4gqCSob49/gu6/7rLJEm/WL5dc5dt1Tt7jtK6AgDoVwgqGezHX/uSbplYqbCJjFn5wTPv62cvbGPcCgCg37BMH/5f9ObmZhUXF6upqUlFRUVul2MLY4zW/s9Rrf7oiJ5/f7+6w0ZXDC3SzLFDdcvEKg0q8LtdIgAASUnm32+CSh/y1q4jum/ZVrV0dkuSyotydO+U4bpuVJmGFOa4XB0AAIkhqFzEjrcG9MLmei17v177T7RLkixLmnjJAE25okxfGlygr18+WL4sevUAAJmJoNIPtHQGtXTjfr3xYYP+u74xbt8XSnL1469/UWMrSzRscL6KcrLdKRIAgLMgqPQzBxs79OaOBr2/94Q27ftcx1oDsX1ej6Wrqkt0eVmhhg3K1xcH52tEeZG+UJLrYsUAgP6MoNKPdQZDWrpxv978sEH7jrfpSEvgrMeVF+Xo8vJCja4oUmFOtr44OF/VpXkqK8rRgLxsWZblcOUAgP6izwWVRYsW6fe//70aGho0duxYPfHEE5o8efIFzyOoXNj+4+3atO+E9h5r095jbfrkaKv2HGlV6DzPEcr2WhpSmKMhRX6NKCtUSZ5P+T6vhhT5NSDPp5I8n0rzs1U5IE/BUFgF/iyCDQAgYcn8+53lUE3n9MILL2jevHl66qmnVFNTo8cee0zTpk3T7t27NWTIELfL6/OqB+apemBe3LbmzqA+PtKqDX89rkONnWruDOqTo6062NipE21dCoaMDjR26EBjh7bub7zgZ+Rke1RWlKNAMKzy4hzlZnuV5bXkz/JqYL5PeX6vmju6ZWQ0fEiBinOzVZiTLZ/XUntXSO1dIZXkZevyskJZigwOlixleSz5sjzK9nqU7bWU5fUoy2Mp2+uR10MwAoD+wPUWlZqaGk2aNElPPvmkJCkcDquqqkr33nuvHnzwwfOeS4tK+nV1h3W0NaDDzZ061NipDw40Ktht1Bbo1tHWgD5v71Jje1DHWgJqCXS7VqdlSdmeSGDJ8kbCSzTEZHkjISfLc/Jnr0fZJ4/zWJa8HkuWZcljSV4r8rPXExnPE93v9UTeI/qzx4q8JJ38OVKDx7Ik67RtivypM373eE6dGzlPce8XfS/LUqy26LmntlmyJHk8kX0X4vHEf8doo1f0zNNbwU5tO+NPnXHSWc7vce5pB5/5mTrjGOt879uj3tO/3bmOia/pbHWd2fgXX4OlUNgo0B2SL8ujLI+nx/HJSOncBO6xPZ+bwrm9PrkvftcUak7pc1M4t5efnOf3pn3Nrj7TotLV1aW6ujrNnz8/ts3j8Wjq1Klav359j+MDgYACgVNjLpqbmx2psz/xZXn0hZLcyGDbasWe5nwmY4yOt3UpN9uroy0BHWkJyJflUUNTp7pCYXWHwuoMhnW8NaDWrm4V52arO2S073ibWjq71dIZVHfIKNfnVW62V/Wfd+hwc6eMMTKSjJFCYaOuUFhd3T1X4jVG6gqFpZCkoL3XBAD6s2+NrdDjt4137fNdDSrHjh1TKBRSWVlZ3PaysjLt2rWrx/ELFizQb37zG6fKw3lYlhVL2Pn+LF06KD+yoyr9n2WMUShs1B02CobC6g4ZBcORP0PRbaft6w6HFTx932nbwsbEQlDsZxP5ORQ+42WMQqHI50YDVPScsNGpbeH4fcaYyH6d/DO27bRzFf35tD9Pftfo76efG33/6Of2vEZn/C6jcFhx3zF6LSP7e55rzthgztgffd+4c84493y19Tj3jHscX8O53/fMus5VU3wNZ/9O5rQqots8lqWcbI+6usPqCqXa4Jza+am2d6ejuTzVRveUr2Cq18Dl+tPxJqlfw9Tewe/yulyuj1FJxvz58zVv3rzY783NzaqqsuFfRmQUy7JOduFIOdlet8sBADjI1aAyaNAgeb1eHT58OG774cOHVV5e3uN4v98vv59n2wAA0F+42p7j8/k0YcIErV69OrYtHA5r9erVqq2tdbEyAACQCVzv+pk3b57uuOMOTZw4UZMnT9Zjjz2mtrY23XnnnW6XBgAAXOZ6UPn+97+vo0eP6uGHH1ZDQ4PGjRunlStX9hhgCwAA+h/X11FJBeuoAADQ9yTz77e7c44AAADOg6ACAAAyFkEFAABkLIIKAADIWAQVAACQsQgqAAAgYxFUAABAxiKoAACAjEVQAQAAGcv1JfRTEV1Ut7m52eVKAABAoqL/bieyOH6fDiotLS2SpKqqKpcrAQAAyWppaVFxcfF5j+nTz/oJh8M6ePCgCgsLZVlWWt+7ublZVVVVqq+v5zlCLuEeuI974D7ugfu4B+lnjFFLS4sqKirk8Zx/FEqfblHxeDyqrKy09TOKior4D9Nl3AP3cQ/cxz1wH/cgvS7UkhLFYFoAAJCxCCoAACBjEVTOwe/361e/+pX8fr/bpfRb3AP3cQ/cxz1wH/fAXX16MC0AALi40aICAAAyFkEFAABkLIIKAADIWAQVAACQsQgqZ7Fo0SJdeumlysnJUU1Njd5//323S7porFu3TjNnzlRFRYUsy9Irr7wSt98Yo4cfflhDhw5Vbm6upk6dqj179sQdc+LECc2aNUtFRUUqKSnRXXfdpdbWVge/Rd+2YMECTZo0SYWFhRoyZIi+/e1va/fu3XHHdHZ2avbs2Ro4cKAKCgr03e9+V4cPH447Zv/+/ZoxY4by8vI0ZMgQ/fznP1d3d7eTX6XPWrx4scaMGRNbQKy2tlZvvPFGbD/X33kLFy6UZVm6//77Y9u4D5mBoHKGF154QfPmzdOvfvUrbdmyRWPHjtW0adN05MgRt0u7KLS1tWns2LFatGjRWff/4z/+ox5//HE99dRT2rhxo/Lz8zVt2jR1dnbGjpk1a5Z27NihVatWacWKFVq3bp3uvvtup75Cn7d27VrNnj1bGzZs0KpVqxQMBnX99derra0tdszPfvYzvf7663rxxRe1du1aHTx4UN/5zndi+0OhkGbMmKGuri699957+vd//3c9++yzevjhh934Sn1OZWWlFi5cqLq6Om3evFnf/OY3ddNNN2nHjh2SuP5O27Rpk5YsWaIxY8bEbec+ZAiDOJMnTzazZ8+O/R4KhUxFRYVZsGCBi1VdnCSZ5cuXx34Ph8OmvLzc/P73v49ta2xsNH6/3zz//PPGGGN27txpJJlNmzbFjnnjjTeMZVnmwIEDjtV+MTly5IiRZNauXWuMiVzz7Oxs8+KLL8aO+eijj4wks379emOMMX/605+Mx+MxDQ0NsWMWL15sioqKTCAQcPYLXCQGDBhgnn76aa6/w1paWsxll11mVq1aZb7+9a+buXPnGmP4e5BJaFE5TVdXl+rq6jR16tTYNo/Ho6lTp2r9+vUuVtY/7N27Vw0NDXHXv7i4WDU1NbHrv379epWUlGjixImxY6ZOnSqPx6ONGzc6XvPFoKmpSZJUWloqSaqrq1MwGIy7DyNHjlR1dXXcfbjyyitVVlYWO2batGlqbm6OtQogMaFQSMuWLVNbW5tqa2u5/g6bPXu2ZsyYEXe9Jf4eZJI+/VDCdDt27JhCoVDcf3SSVFZWpl27drlUVf/R0NAgSWe9/tF9DQ0NGjJkSNz+rKwslZaWxo5B4sLhsO6//35dc801Gj16tKTINfb5fCopKYk79sz7cLb7FN2HC9u+fbtqa2vV2dmpgoICLV++XKNGjdK2bdu4/g5ZtmyZtmzZok2bNvXYx9+DzEFQAfqx2bNn68MPP9S7777rdin9zogRI7Rt2zY1NTXppZde0h133KG1a9e6XVa/UV9fr7lz52rVqlXKyclxuxycB10/pxk0aJC8Xm+PUd2HDx9WeXm5S1X1H9FrfL7rX15e3mNgc3d3t06cOME9StKcOXO0YsUKvfXWW6qsrIxtLy8vV1dXlxobG+OOP/M+nO0+Rffhwnw+n4YPH64JEyZowYIFGjt2rP7whz9w/R1SV1enI0eO6KqrrlJWVpaysrK0du1aPf7448rKylJZWRn3IUMQVE7j8/k0YcIErV69OrYtHA5r9erVqq2tdbGy/mHYsGEqLy+Pu/7Nzc3auHFj7PrX1taqsbFRdXV1sWPWrFmjcDismpoax2vui4wxmjNnjpYvX641a9Zo2LBhcfsnTJig7OzsuPuwe/du7d+/P+4+bN++PS40rlq1SkVFRRo1apQzX+QiEw6HFQgEuP4OmTJlirZv365t27bFXhMnTtSsWbNiP3MfMoTbo3kzzbJly4zf7zfPPvus2blzp7n77rtNSUlJ3Khu9F5LS4vZunWr2bp1q5Fk/umf/sls3brVfPrpp8YYYxYuXGhKSkrMq6++aj744ANz0003mWHDhpmOjo7Ye9xwww1m/PjxZuPGjebdd981l112mbntttvc+kp9zj333GOKi4vN22+/bQ4dOhR7tbe3x475yU9+Yqqrq82aNWvM5s2bTW1tramtrY3t7+7uNqNHjzbXX3+92bZtm1m5cqUZPHiwmT9/vhtfqc958MEHzdq1a83evXvNBx98YB588EFjWZb585//bIzh+rvl9Fk/xnAfMgVB5SyeeOIJU11dbXw+n5k8ebLZsGGD2yVdNN566y0jqcfrjjvuMMZEpij/8pe/NGVlZcbv95spU6aY3bt3x73H8ePHzW233WYKCgpMUVGRufPOO01LS4sL36ZvOtv1l2T+7d/+LXZMR0eH+elPf2oGDBhg8vLyzM0332wOHToU9z779u0z06dPN7m5uWbQoEHm7/7u70wwGHT42/RNf/u3f2suueQS4/P5zODBg82UKVNiIcUYrr9bzgwq3IfMYBljjDttOQAAAOfHGBUAAJCxCCoAACBjEVQAAEDGIqgAAICMRVABAAAZi6ACAAAyFkEFAABkLIIKAADIWAQVAACQsQgqAFzX1dWl4cOH67333nP0c1euXKlx48YpHA47+rkAEkdQAZCQtWvXauTIkRo3blzca8yYMbr33nslSTU1NT32jxs3TsOHD1cgEDjnez/11FMaNmyYrr766oRqCQaDeuCBB3TllVcqPz9fFRUVuv3223Xw4MG4406cOKFZs2apqKhIJSUluuuuu9Ta2hrbf8MNNyg7O1tLly7txRUB4ASCCoCEdHR06NZbb9W2bdviXq+99pqOHj0qSbIsq8f+bdu2qbKyUud6rJgxRk8++aTuuuuuhGtpb2/Xli1b9Mtf/lJbtmzRyy+/rN27d+tb3/pW3HGzZs3Sjh07tGrVKq1YsULr1q3T3XffHXfMD3/4Qz3++ONJXg0ATiGoAHBVXV2dPvnkE82YMSO27T/+4z9UUFCgPXv2xLb99Kc/1ciRI9Xe3q7i4mKtWrVKt9xyi0aMGKGvfOUrevLJJ1VXV6f9+/dLkj766COtXLlSTz/9tGpqavTVr35VTzzxhJYtWxbX8jJz5kxt3rxZn3zyiXNfGkDCCCoAXPXOO+/o8ssvV2FhYWzb7bffrhtvvFGzZs1Sd3e3/vM//1NPP/20li5dqry8vLO+T1NTkyzLUklJiSRp/fr1Kikp0cSJE2PHTJ06VR6PRxs3boxtq66uVllZmd555x17viCAlBBUALjq008/VUVFRY/tS5Ys0aFDh3Tffffprrvu0q9//WtNmDDhrO/R2dmpBx54QLfddpuKiookSQ0NDRoyZEjccVlZWSotLVVDQ0Pc9oqKCn366adp+kYA0inL7QIA9G8dHR3KycnpsX3AgAF65plnNG3aNF199dV68MEHz3p+MBjULbfcImOMFi9e3KsacnNz1d7e3qtzAdiLFhUArho0aJA+//zzs+5bt26dvF6vDh06pLa2th77oyHl008/1apVq2KtKZJUXl6uI0eOxB3f3d2tEydOqLy8PG77iRMnNHjw4DR8GwDpRlAB4Krx48dr165dPWYFvffee3r00Uf1+uuvq6CgQHPmzInbHw0pe/bs0V/+8hcNHDgwbn9tba0aGxtVV1cX27ZmzRqFw2HV1NTEtnV2duqTTz7R+PHjbfh2AFJF1w8AV33jG99Qa2urduzYodGjR0uSWlpa9IMf/ED33Xefpk+frsrKSk2aNEkzZ87U9773PQWDQX3ve9/Tli1btGLFCoVCodi4k9LSUvl8Pl1xxRW64YYb9KMf/UhPPfWUgsGg5syZo1tvvTVuTMyGDRvk9/tVW1vryvcHcH60qABw1cCBA3XzzTfHLbo2d+5c5efn65FHHpEkXXnllXrkkUf04x//WAcOHNCBAwf02muv6bPPPtO4ceM0dOjQ2Ov01W2XLl2qkSNHasqUKbrxxhv11a9+Vf/yL/8S9/nPP/+8Zs2adc7ZRADcRYsKANc99NBDuu666/TQQw+poKBA//qv/9rjmHnz5mnevHmx38+1gNzpSktL9dxzz51z/7Fjx/TSSy9p8+bNvSscgO1oUQHgujFjxujRRx/V3r17Hf3cffv26Z//+Z81bNgwRz8XQOJoUQGQkOLiYq1YsUIrVqzosW/atGmS1GOBtdN5POf//6If/vCHKdeYrIkTJ56zXgCZwTKJtJ8CAAC4gK4fAACQsQgqAAAgYxFUAABAxiKoAACAjEVQAQAAGYugAgAAMhZBBQAAZKz/DxbGWFnYOSHFAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# coding: utf-8\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "import numpy as np\n",
    "from common import config\n",
    "# GPU에서 실행하려면 아래 주석을 해제하세요(CuPy 필요).\n",
    "# ===============================================\n",
    "# config.GPU = True\n",
    "# ===============================================\n",
    "import pickle\n",
    "from common.trainer import Trainer\n",
    "from common.optimizer import Adam\n",
    "# from cbow import CBOW\n",
    "# from skip_gram import SkipGram\n",
    "from common.util import create_contexts_target, to_cpu, to_gpu\n",
    "from dataset import ptb\n",
    "\n",
    "\n",
    "# 하이퍼파라미터 설정\n",
    "window_size = 5\n",
    "hidden_size = 100\n",
    "batch_size = 100\n",
    "# max_epoch = 10\n",
    "max_epoch = 1\n",
    "\n",
    "# 데이터 읽기\n",
    "corpus, word_to_id, id_to_word = ptb.load_data('train')\n",
    "vocab_size = len(word_to_id)\n",
    "\n",
    "contexts, target = create_contexts_target(corpus, window_size)\n",
    "if config.GPU:\n",
    "    contexts, target = to_gpu(contexts), to_gpu(target)\n",
    "\n",
    "# 모델 등 생성\n",
    "model = CBOW(vocab_size, hidden_size, window_size, corpus)\n",
    "# model = SkipGram(vocab_size, hidden_size, window_size, corpus)\n",
    "optimizer = Adam()\n",
    "trainer = Trainer(model, optimizer)\n",
    "\n",
    "# 학습 시작\n",
    "trainer.fit(contexts, target, max_epoch, batch_size)\n",
    "trainer.plot()\n",
    "\n",
    "# 나중에 사용할 수 있도록 필요한 데이터 저장\n",
    "word_vecs = model.word_vecs\n",
    "if config.GPU:\n",
    "    word_vecs = to_cpu(word_vecs)\n",
    "params = {}\n",
    "params['word_vecs'] = word_vecs.astype(np.float16)\n",
    "params['word_to_id'] = word_to_id\n",
    "params['id_to_word'] = id_to_word\n",
    "pkl_file = 'cbow_params.pkl'  # or 'skipgram_params.pkl'\n",
    "with open(pkl_file, 'wb') as f:\n",
    "    pickle.dump(params, f, -1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.3 CBOW 모델 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[query] you\n",
      " is: 1.0\n",
      " mr.: 1.0\n",
      " of: 1.0\n",
      " the: 1.0\n",
      " <eos>: 1.0\n",
      "\n",
      "[query] year\n",
      " mr.: 1.0009765625\n",
      " are: 1.0009765625\n",
      " an: 1.0009765625\n",
      " board: 1.0\n",
      " the: 1.0\n",
      "\n",
      "[query] car\n",
      " mr.: 1.0009765625\n",
      " workers: 1.0\n",
      " rep.: 1.0\n",
      " reported: 1.0\n",
      " with: 1.0\n",
      "\n",
      "[query] toyota\n",
      " the: 0.9990234375\n",
      " to: 0.9990234375\n",
      " years: 0.9990234375\n",
      " revenue: 0.9990234375\n",
      " d.: 0.9990234375\n",
      "--------------------------------------------------\n",
      "\n",
      "[analogy] king:man = queen:?\n",
      " and: 9.1015625\n",
      " <eos>: 8.859375\n",
      " to: 8.734375\n",
      " 's: 8.7265625\n",
      " of: 8.59375\n",
      "\n",
      "[analogy] take:took = go:?\n",
      " and: 9.1875\n",
      " <eos>: 8.9375\n",
      " to: 8.8125\n",
      " 's: 8.8046875\n",
      " of: 8.671875\n",
      "\n",
      "[analogy] car:cars = child:?\n",
      " and: 9.125\n",
      " <eos>: 8.8828125\n",
      " to: 8.7578125\n",
      " 's: 8.75\n",
      " of: 8.6171875\n",
      "\n",
      "[analogy] good:better = bad:?\n",
      " and: 9.171875\n",
      " <eos>: 8.921875\n",
      " to: 8.796875\n",
      " 's: 8.7890625\n",
      " of: 8.65625\n"
     ]
    }
   ],
   "source": [
    "# coding: utf-8\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from common.util import most_similar, analogy\n",
    "import pickle\n",
    "\n",
    "\n",
    "pkl_file = 'cbow_params.pkl'\n",
    "# pkl_file = 'skipgram_params.pkl'\n",
    "\n",
    "with open(pkl_file, 'rb') as f:\n",
    "    params = pickle.load(f)\n",
    "    word_vecs = params['word_vecs']\n",
    "    word_to_id = params['word_to_id']\n",
    "    id_to_word = params['id_to_word']\n",
    "\n",
    "# 가장 비슷한(most similar) 단어 뽑기\n",
    "querys = ['you', 'year', 'car', 'toyota']\n",
    "for query in querys:\n",
    "    most_similar(query, word_to_id, id_to_word, word_vecs, top=5)\n",
    "\n",
    "# 유추(analogy) 작업\n",
    "print('-'*50)\n",
    "analogy('king', 'man', 'queen',  word_to_id, id_to_word, word_vecs)\n",
    "analogy('take', 'took', 'go',  word_to_id, id_to_word, word_vecs)\n",
    "analogy('car', 'cars', 'child',  word_to_id, id_to_word, word_vecs)\n",
    "analogy('good', 'better', 'bad',  word_to_id, id_to_word, word_vecs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
